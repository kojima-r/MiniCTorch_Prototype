{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20211004_minictorch_cross_entropy_loss.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNbOjMLstMWS0Lf4MllO/gp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Sml8FMQqbgEj"},"source":["cross entropy loss　分類問題"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULQtL8IeXTg2","executionInfo":{"status":"ok","timestamp":1635254651755,"user_tz":-540,"elapsed":337,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"4f5fa461-77ca-4c46-a415-11c2eada7a2c"},"source":["#　colaboraory用: Google drive をマウントする\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NujIexoFXUmL","executionInfo":{"status":"ok","timestamp":1635254653404,"user_tz":-540,"elapsed":310,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"e452f85c-8390-43e0-c334-96ac209614f1"},"source":["# colaboratory用: フォルダを移る\n","%cd \"drive/My Drive/Colab Notebooks/\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks\n"]}]},{"cell_type":"markdown","metadata":{"id":"0DNl9nIDfY0l"},"source":["フォルダは自分の指定のものに変更して下さい。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gR9cSFPNfVA4","executionInfo":{"status":"ok","timestamp":1635254656800,"user_tz":-540,"elapsed":395,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"137b7dab-ec24-427b-9a3b-76f162405136"},"source":["%cd \"ctorch210929/MiniCTorch_Prototype/notebook\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/ctorch210929/MiniCTorch_Prototype/notebook\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPPGcVEQ7fwE","executionInfo":{"status":"ok","timestamp":1635254661368,"user_tz":-540,"elapsed":3095,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"df4ee9fc-dc77-41e5-c71b-26833c5d7027"},"source":["! pip install lark-parser"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lark-parser in /usr/local/lib/python3.7/dist-packages (0.12.0)\n"]}]},{"cell_type":"code","metadata":{"id":"vuIJaurj7brd"},"source":["import sys\n","sys.path.append(\"../\")\n","\n","import json\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import minictorch.generator as GN\n","import minictorch.converter as CV"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWUPb5h0Blqx"},"source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing   import StandardScaler\n","\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fuAfJop8BpYI"},"source":["データ読み込み"]},{"cell_type":"code","metadata":{"id":"5FYRis-rBr_Y"},"source":["# データ読み込み\n","iris = datasets.load_iris()\n","data   = iris['data']\n","target = iris['target']\n","\n","# 学習データと検証データに分割\n","x_train, x_valid, y_train, y_valid = train_test_split( data, target, shuffle=True )\n","\n","# 特徴量の標準化\n","scaler = StandardScaler()\n","scaler.fit( x_train )\n","\n","x_train = scaler.transform(x_train)\n","x_valid = scaler.transform(x_valid)\n","\n","# Tensor型に変換\n","# 学習に入れるときはfloat型 or long型になっている必要があるのここで変換してしまう\n","x_train = torch.from_numpy(x_train).float()\n","y_train = torch.from_numpy(y_train).long()\n","x_valid = torch.from_numpy(x_valid).float()\n","y_valid = torch.from_numpy(y_valid).long()\n","\n","#print('x_train : ', x_train.shape)\n","#print('y_train : ', y_train.shape)\n","#print('x_valid : ', x_valid.shape)\n","#print('y_valid : ', y_valid.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cDivgOEAB-wC"},"source":["DataSetとDataLoaderの生成"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-AznF7ZCEEJ","executionInfo":{"status":"ok","timestamp":1635254672250,"user_tz":-540,"elapsed":471,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"9829e7a3-351b-4174-ae30-55f2db79ad05"},"source":["train_dataset = TensorDataset(x_train, y_train)\n","valid_dataset = TensorDataset(x_valid, y_valid)\n","\n","# indexを指定すればデータを取り出すことができます。\n","index = 0\n","print( train_dataset.__getitem__(index)[0].size() )\n","print( train_dataset.__getitem__(index)[1] )\n","\n","\n","batch_size = 112\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n","\n","# 動作確認\n","# こんな感じでバッチ単位で取り出す子ができます。\n","# イテレータに変換\n","batch_iterator = iter(train_dataloader)\n","\n","# 1番目の要素を取り出す\n","inputs, labels = next(batch_iterator)\n","print(inputs.size())\n","print(labels.size())\n","#print(inputs)\n","print(labels)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4])\n","tensor(2)\n","torch.Size([112, 4])\n","torch.Size([112])\n","tensor([1, 0, 0, 1, 2, 0, 2, 2, 1, 0, 2, 2, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1,\n","        1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 2, 0, 1, 2, 0, 2,\n","        2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 1,\n","        1, 1, 0, 2, 1, 0, 0, 1, 0, 2, 0, 2, 1, 2, 2, 0, 0, 0, 1, 1, 2, 0, 2, 2,\n","        0, 2, 1, 0, 2, 1, 1, 1, 1, 0, 1, 1, 2, 2, 2, 1])\n"]}]},{"cell_type":"markdown","metadata":{"id":"8Io-p4ogJysT"},"source":["ニューラルネットワークの定義"]},{"cell_type":"code","metadata":{"id":"FMLT7mbxauCN"},"source":["class Net(nn.Module):    \n","    def __init__(self,t):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(4, 64)\n","        self.fc2 = nn.Linear(64, 3)\n","        self.target = t\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        #x = F.log_softmax(x, dim=1)\n","        self.out = x\n","\n","        loss = nn.CrossEntropyLoss()\n","        #loss = nn.NLLLoss()\n","        output = loss(x,self.target)\n","        return output\n","        \n","\n","class Net2(nn.Module):    \n","    def __init__(self):\n","        super(Net2, self).__init__()\n","        self.fc1 = nn.Linear(4, 64)\n","        self.fc2 = nn.Linear(64, 3)\n","        #self.fc1 = nn.Linear(4, 128)\n","        #self.fc2 = nn.Linear(128, 3)\n","    \n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        #x = F.relu(self.fc2(x))\n","        x = self.fc2(x)\n","        #x = F.softmax(x, dim=1)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yu6J3uzDVsp"},"source":["def generate_json( json_path, input, target ):\n","\n","    model = Net( target )\n","    model.eval()\n","    with torch.no_grad():\n","        print(\"[SAVE]\", json_path )\n","        GN.generate_minictorch_file( model, input, json_path )\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gavYhJ2Z6tft","executionInfo":{"status":"ok","timestamp":1635254688054,"user_tz":-540,"elapsed":319,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"012099e2-76b6-4f31-eaf2-1151f6f2f1b1"},"source":["torch.manual_seed( 1 )\n","\n","print(\"inputs\",inputs)\n","print(\"target\",labels)\n","inputs.requires_grad = True\n","\n","project = 'cse1'\n","json_path = './network/' + project +'.json'\n","\n","model = generate_json( json_path, inputs, labels )\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["inputs tensor([[-0.1710, -0.6233,  0.4113,  0.1211],\n","        [-1.4718,  1.2634, -1.5500, -1.2994],\n","        [-1.5900, -1.8025, -1.3819, -1.1703],\n","        [ 1.2480,  0.0842,  0.6354,  0.3793],\n","        [ 0.6567,  0.0842,  0.9716,  0.7667],\n","        [-0.9988,  1.0276, -1.3819, -1.1703],\n","        [ 0.7750, -0.1516,  1.1397,  1.2833],\n","        [ 0.5385,  0.7917,  1.0277,  1.5415],\n","        [-0.8805, -1.3308, -0.4293, -0.1372],\n","        [-0.9988,  0.7917, -1.2698, -1.2994],\n","        [ 0.6567, -0.8591,  0.8595,  0.8959],\n","        [ 2.0757, -0.1516,  1.5880,  1.1541],\n","        [ 0.3020, -0.3874,  0.5233,  0.2502],\n","        [-0.8805,  1.7351, -1.0457, -1.0411],\n","        [-1.1170,  0.0842, -1.2698, -1.2994],\n","        [ 0.5385, -0.6233,  0.7475,  0.3793],\n","        [-1.4718,  0.0842, -1.2698, -1.2994],\n","        [ 0.7750, -0.6233,  0.4673,  0.3793],\n","        [ 0.3020, -0.6233,  0.1311,  0.1211],\n","        [-1.3535,  0.3201, -1.3819, -1.2994],\n","        [-0.5258,  0.7917, -1.1577, -1.2994],\n","        [ 0.0655, -0.1516,  0.7475,  0.7667],\n","        [-0.5258,  0.7917, -1.2698, -1.0411],\n","        [-0.2893, -0.3874, -0.0931,  0.1211],\n","        [ 0.5385, -1.8025,  0.3552,  0.1211],\n","        [ 1.4845, -0.1516,  1.1958,  1.1541],\n","        [-0.9988,  0.7917, -1.2138, -1.0411],\n","        [-0.9988, -2.5100, -0.1491, -0.2663],\n","        [ 0.5385, -1.3308,  0.6914,  0.8959],\n","        [-1.7083, -0.1516, -1.3819, -1.2994],\n","        [-0.8805,  1.0276, -1.3258, -1.1703],\n","        [ 0.5385,  0.5559,  0.5233,  0.5085],\n","        [-0.0528, -0.8591,  0.7475,  0.8959],\n","        [ 1.0115,  0.5559,  1.0837,  1.1541],\n","        [ 0.1837, -2.0383,  0.6914,  0.3793],\n","        [ 0.3020, -0.6233,  0.5233, -0.0081],\n","        [ 0.5385,  0.5559,  1.2518,  1.6707],\n","        [-0.4075, -1.5666, -0.0370, -0.2663],\n","        [-0.1710,  3.1501, -1.2698, -1.0411],\n","        [-1.8265, -0.1516, -1.4939, -1.4285],\n","        [ 1.3662,  0.3201,  0.5233,  0.2502],\n","        [ 0.6567, -0.3874,  0.2992,  0.1211],\n","        [ 0.6567,  0.3201,  0.8595,  1.4124],\n","        [-1.2353,  0.7917, -1.2138, -1.2994],\n","        [-0.0528, -1.0950,  0.1311, -0.0081],\n","        [ 1.0115, -0.1516,  0.8035,  1.4124],\n","        [-0.5258,  1.9709, -1.1577, -1.0411],\n","        [ 1.7210, -0.3874,  1.4199,  0.7667],\n","        [ 1.2480,  0.3201,  1.0837,  1.4124],\n","        [ 0.5385, -1.3308,  0.6354,  0.3793],\n","        [-0.8805,  0.7917, -1.2698, -1.2994],\n","        [-0.2893, -0.1516,  0.1871,  0.1211],\n","        [-1.2353, -0.1516, -1.3258, -1.1703],\n","        [ 0.0655, -0.1516,  0.2432,  0.3793],\n","        [-0.9988, -0.1516, -1.2138, -1.2994],\n","        [-1.7083, -0.3874, -1.3258, -1.2994],\n","        [-0.5258,  1.9709, -1.3819, -1.0411],\n","        [-0.7623, -0.8591,  0.0750,  0.2502],\n","        [-0.4075, -1.8025,  0.1311,  0.1211],\n","        [-1.4718,  0.7917, -1.3258, -1.1703],\n","        [ 0.1837, -0.3874,  0.4113,  0.3793],\n","        [ 1.0115,  0.0842,  1.0277,  1.5415],\n","        [ 0.0655,  0.3201,  0.5794,  0.7667],\n","        [ 0.7750,  0.3201,  0.7475,  1.0250],\n","        [ 2.4305,  1.7351,  1.4759,  1.0250],\n","        [-0.4075, -1.3308,  0.1311,  0.1211],\n","        [-0.6440,  1.4992, -1.2698, -1.2994],\n","        [-0.7623,  1.0276, -1.2698, -1.2994],\n","        [ 1.6027,  1.2634,  1.3078,  1.6707],\n","        [-0.7623,  2.4426, -1.2698, -1.4285],\n","        [-0.1710, -1.3308,  0.6914,  1.0250],\n","        [-0.5258, -0.1516,  0.4113,  0.3793],\n","        [ 0.1837, -0.8591,  0.7475,  0.5085],\n","        [-0.1710, -1.0950, -0.1491, -0.2663],\n","        [-0.8805,  1.7351, -1.2138, -1.2994],\n","        [ 2.1940, -0.6233,  1.6440,  1.0250],\n","        [ 0.1837, -2.0383,  0.1311, -0.2663],\n","        [-0.1710,  1.7351, -1.1577, -1.1703],\n","        [-0.9988,  1.2634, -1.3258, -1.2994],\n","        [-0.1710, -0.1516,  0.2432, -0.0081],\n","        [-0.9988,  0.3201, -1.4379, -1.2994],\n","        [-0.0528, -0.6233,  0.7475,  1.5415],\n","        [-0.9988,  1.0276, -1.2138, -0.7829],\n","        [-0.2893, -0.6233,  0.6354,  1.0250],\n","        [ 1.0115,  0.0842,  0.5233,  0.3793],\n","        [-0.0528, -0.8591,  0.7475,  0.8959],\n","        [ 0.6567, -0.6233,  1.0277,  1.2833],\n","        [-1.1170,  0.0842, -1.2698, -1.4285],\n","        [-1.7083,  0.3201, -1.3819, -1.2994],\n","        [-1.2353, -0.1516, -1.3258, -1.4285],\n","        [ 0.4202, -0.3874,  0.2992,  0.1211],\n","        [-0.2893, -0.1516,  0.4113,  0.3793],\n","        [ 0.5385, -0.3874,  1.0277,  0.7667],\n","        [-1.2353,  0.7917, -1.0457, -1.2994],\n","        [ 1.8392, -0.6233,  1.3078,  0.8959],\n","        [ 1.1297, -0.1516,  0.9716,  1.1541],\n","        [-0.8805,  1.0276, -1.3258, -1.2994],\n","        [ 2.1940,  1.7351,  1.6440,  1.2833],\n","        [-0.2893, -1.3308,  0.0750, -0.1372],\n","        [-1.1170,  1.2634, -1.3258, -1.4285],\n","        [ 0.6567, -0.6233,  1.0277,  1.1541],\n","        [ 1.1297, -0.6233,  0.5794,  0.2502],\n","        [-0.1710, -0.6233,  0.1871,  0.1211],\n","        [ 0.8932, -0.1516,  0.3552,  0.2502],\n","        [ 1.0115, -0.1516,  0.6914,  0.6376],\n","        [-1.2353,  0.0842, -1.2138, -1.2994],\n","        [ 0.3020, -0.1516,  0.4673,  0.2502],\n","        [ 1.0115,  0.0842,  0.3552,  0.2502],\n","        [ 1.1297,  0.3201,  1.1958,  1.4124],\n","        [ 2.1940, -1.0950,  1.7561,  1.4124],\n","        [ 1.0115,  0.5559,  1.0837,  1.6707],\n","        [ 0.6567,  0.3201,  0.4113,  0.3793]], requires_grad=True)\n","target tensor([1, 0, 0, 1, 2, 0, 2, 2, 1, 0, 2, 2, 1, 0, 0, 2, 0, 1, 1, 0, 0, 2, 0, 1,\n","        1, 2, 0, 1, 2, 0, 0, 1, 2, 2, 2, 1, 2, 1, 0, 0, 1, 1, 2, 0, 1, 2, 0, 2,\n","        2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 1,\n","        1, 1, 0, 2, 1, 0, 0, 1, 0, 2, 0, 2, 1, 2, 2, 0, 0, 0, 1, 1, 2, 0, 2, 2,\n","        0, 2, 1, 0, 2, 1, 1, 1, 1, 0, 1, 1, 2, 2, 2, 1])\n","[SAVE] ./network/cse1.json\n","skip: Net/Linear[fc1]/weight/26\n","skip: Net/Linear[fc1]/weight/26\n","skip: Net/Linear[fc2]/weight/29\n","skip: Net/Linear[fc2]/weight/29\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5EtFEsQ0sLW1","executionInfo":{"status":"ok","timestamp":1635254696015,"user_tz":-540,"elapsed":341,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"85d58be6-2ec3-42b3-ac22-b5595a14eb01"},"source":["CV.convert_json( project, \"./src\", model, inputs, json_path )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[JSON] ./network/cse1.json\n","{'name': 'Net/Linear[fc1]/weight/35', 'op': 'prim::GetAttr', 'in': [], 'output_id': 0, 'shape': [], 'out': [3], 'sorted_id': 1}\n","{'name': 'Net/Linear[fc1]/bias/34', 'op': 'prim::GetAttr', 'in': [], 'output_id': 0, 'shape': [], 'out': [3], 'sorted_id': 2}\n","{'name': 'Net/Linear[fc2]/weight/38', 'op': 'prim::GetAttr', 'in': [], 'output_id': 0, 'shape': [], 'out': [7], 'sorted_id': 5}\n","{'name': 'Net/Linear[fc2]/bias/37', 'op': 'prim::GetAttr', 'in': [], 'output_id': 0, 'shape': [], 'out': [7], 'sorted_id': 6}\n","[PARAM] ./src/cse1_param.cpp\n","{'name': 'input/x', 'op': 'IO Node', 'in': [], 'output_id': 0, 'shape': [112, 4], 'out': [3], 'sorted_id': 0}\n","{'name': 'Net/Linear[fc1]/weight/35', 'op': 'prim::GetAttr', 'in': [], 'output_id': 0, 'shape': [], 'out': [3], 'sorted_id': 1}\n","Net/Linear[fc1]/weight/35  ->  fc1_weight\n","{'name': 'Net/Linear[fc1]/bias/34', 'op': 'prim::GetAttr', 'in': [], 'output_id': 0, 'shape': [], 'out': [3], 'sorted_id': 2}\n","Net/Linear[fc1]/bias/34  ->  fc1_bias\n","{'name': 'Net/Linear[fc1]/input.1', 'op': 'aten::linear', 'in': [0, 1, 2], 'output_id': 0, 'shape': [112, 64], 'out': [4], 'sorted_id': 3}\n","{'name': 'Net/input.3', 'op': 'aten::relu', 'in': [3], 'output_id': 0, 'shape': [112, 64], 'out': [7], 'sorted_id': 4}\n","{'name': 'Net/Linear[fc2]/weight/38', 'op': 'prim::GetAttr', 'in': [], 'output_id': 0, 'shape': [], 'out': [7], 'sorted_id': 5}\n","Net/Linear[fc2]/weight/38  ->  fc2_weight\n","{'name': 'Net/Linear[fc2]/bias/37', 'op': 'prim::GetAttr', 'in': [], 'output_id': 0, 'shape': [], 'out': [7], 'sorted_id': 6}\n","Net/Linear[fc2]/bias/37  ->  fc2_bias\n","{'name': 'Net/Linear[fc2]/input', 'op': 'aten::linear', 'in': [4, 5, 6], 'output_id': 0, 'shape': [112, 3], 'out': [12], 'sorted_id': 7}\n","{'name': 'Net/17', 'op': 'prim::Constant', 'in': [], 'output_id': 0, 'shape': [112], 'constant_value': [1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0], 'out': [12], 'sorted_id': 8}\n","{'name': 'Net/18', 'op': 'prim::Constant', 'in': [], 'output_id': 0, 'shape': [], 'out': [12], 'sorted_id': 9}\n","{'name': 'Net/19', 'op': 'prim::Constant', 'in': [], 'output_id': 0, 'shape': [], 'constant_value': 1.0, 'out': [12], 'sorted_id': 10}\n","{'name': 'Net/20', 'op': 'prim::Constant', 'in': [], 'output_id': 0, 'shape': [], 'constant_value': -100.0, 'out': [12], 'sorted_id': 11}\n","{'name': 'Net/21', 'op': 'aten::cross_entropy_loss', 'in': [7, 8, 9, 10, 11], 'output_id': 0, 'shape': [], 'out': [13], 'sorted_id': 12}\n","{'name': 'output/output.1', 'op': 'IO Node', 'in': [12], 'output_id': 0, 'shape': [], 'out': [], 'sorted_id': 13}\n","[CPP]  ./src/cse1.cpp\n","[MAKE] ./src/Makefile\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X1ox2UOpskhM","executionInfo":{"status":"ok","timestamp":1635254700218,"user_tz":-540,"elapsed":270,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"93516c5d-8d79-4214-aeba-3592741aa0cd"},"source":["# check code\n","with torch.set_grad_enabled(True):\n","  \n","  output = model( inputs )\n","  print(\"output\",output)\n","\n","  model.zero_grad()\n","  output.backward()\n","  print(\"output grad\",output.grad)\n","  print(\"input grad\",inputs.grad)\n","\n","  # ラベルを予測\n","  #print(\"output\", model.out, inputs.size(0))\n","  _, preds = torch.max( model.out, 1 )\n","\n","  # イテレーション結果の計算\n","  epoch_loss = output * inputs.size(0)\n","\n","  # 正解数の合計を更新\n","  epoch_corrects = torch.sum( preds == labels.data )\n","\n","  epoch_loss = epoch_loss / float(inputs.size(0))\n","  epoch_acc  = epoch_corrects.double() / float(inputs.size(0))\n","\n","  epoch=1\n","  print('Train Loss {}: {:.4f} Acc: {:.4f}'.format( epoch, epoch_loss, epoch_acc ))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["output tensor(1.1601, grad_fn=<NllLossBackward>)\n","output grad None\n","input grad tensor([[ 3.8844e-04, -8.2199e-05,  1.4423e-03, -1.0259e-03],\n","        [-1.6304e-03, -5.8838e-04,  3.9302e-04, -3.6282e-04],\n","        [-2.0818e-03, -1.0184e-03,  1.6581e-03, -5.6532e-04],\n","        [-5.1059e-04, -1.2330e-04, -6.4811e-04, -1.0453e-03],\n","        [ 7.5653e-04,  1.1319e-03, -8.5129e-04,  9.5496e-04],\n","        [-1.3675e-03, -5.9082e-04,  3.3255e-04, -3.1672e-04],\n","        [ 4.5632e-04,  1.4719e-03, -3.7993e-04,  7.6784e-04],\n","        [ 4.8434e-04,  1.0216e-03, -1.6423e-04,  8.4509e-04],\n","        [ 9.7461e-04, -3.7618e-04,  1.2009e-03,  4.5496e-04],\n","        [-1.3711e-03, -5.9843e-04,  3.3704e-04, -3.1642e-04],\n","        [ 1.2982e-03,  6.7970e-04, -9.6011e-04,  6.7615e-04],\n","        [ 9.1169e-04,  4.9826e-04, -5.2589e-05,  3.5811e-04],\n","        [-2.7863e-04, -4.9891e-04,  3.3928e-04, -1.6313e-03],\n","        [-1.4834e-03,  3.3193e-04,  3.7000e-04,  3.5512e-04],\n","        [-1.2651e-03, -5.6642e-04,  4.0925e-04, -3.1364e-04],\n","        [ 1.1791e-03,  7.7479e-04, -7.0800e-04,  9.5719e-04],\n","        [-1.3083e-03, -4.5767e-04,  4.0980e-04, -4.6182e-04],\n","        [-3.9223e-04, -3.9509e-04, -8.0082e-05, -1.2079e-03],\n","        [-2.5259e-04, -3.9501e-04,  6.0958e-04, -7.3019e-04],\n","        [-1.3425e-03, -4.8782e-04,  4.1703e-04, -2.9370e-04],\n","        [-1.8885e-03, -5.6379e-04,  3.1331e-04, -3.0840e-04],\n","        [ 9.5422e-04,  9.0379e-04, -1.1787e-03,  1.0079e-03],\n","        [-1.8748e-03, -5.1266e-04,  3.2331e-04, -2.9234e-04],\n","        [ 1.1972e-03, -4.8085e-04,  1.4321e-03, -1.6012e-04],\n","        [-2.5177e-04,  9.5118e-04,  3.3888e-05,  1.3090e-04],\n","        [ 9.4192e-04,  5.3681e-04, -1.3427e-04,  3.4583e-04],\n","        [-1.3511e-03, -6.0248e-04,  3.3974e-04, -3.0940e-04],\n","        [-4.9987e-04,  5.7552e-04,  1.0841e-03,  5.9709e-04],\n","        [ 1.1542e-03,  6.8840e-04, -9.9908e-04,  7.2343e-04],\n","        [-1.1278e-03, -4.4393e-04,  3.7882e-04, -4.7969e-04],\n","        [-1.3013e-03, -5.4991e-04,  3.1263e-04, -2.4436e-04],\n","        [-2.1860e-04, -6.4869e-04, -4.8473e-04, -1.1533e-03],\n","        [ 9.4071e-04,  1.3669e-03, -1.3424e-03,  8.9878e-04],\n","        [ 4.8526e-04,  8.9206e-04, -1.1489e-04,  7.0614e-04],\n","        [ 5.5272e-04,  1.7906e-04, -1.1475e-03,  1.6187e-04],\n","        [-9.4539e-04,  9.0986e-06, -1.3672e-04, -1.6149e-03],\n","        [ 4.6396e-04,  1.0019e-03, -1.3364e-04,  8.8911e-04],\n","        [-2.2910e-04,  8.1768e-04,  1.2406e-03,  4.7157e-04],\n","        [-1.7412e-03,  8.0529e-04,  8.3977e-04,  4.5503e-04],\n","        [-1.0920e-03, -4.7652e-04,  3.1079e-04, -5.3611e-04],\n","        [-5.6062e-04, -1.5488e-04, -6.2743e-04, -1.2166e-03],\n","        [-5.4109e-04,  7.4690e-05, -3.0429e-04, -1.5652e-03],\n","        [ 3.7797e-04,  8.3413e-04, -4.3064e-04,  9.6060e-04],\n","        [-1.4584e-03, -4.5888e-04,  1.2486e-04, -1.8279e-04],\n","        [ 4.2623e-04,  4.6447e-04,  9.2213e-04, -6.2890e-05],\n","        [ 1.9622e-04,  8.5687e-04, -7.0731e-04,  8.9950e-04],\n","        [-1.4426e-03,  3.1408e-04,  3.6349e-04,  3.4754e-04],\n","        [ 1.2525e-03,  9.7738e-04, -6.1879e-04,  4.9618e-04],\n","        [ 5.4788e-04,  8.6140e-04, -4.4527e-04,  5.3427e-04],\n","        [-6.0461e-04,  1.5788e-04, -2.4060e-04, -7.6686e-04],\n","        [-1.5098e-03, -6.4290e-04,  1.1634e-04, -1.7462e-04],\n","        [ 1.0256e-03, -1.3925e-03,  7.8641e-04, -6.9154e-04],\n","        [-1.2417e-03, -4.9671e-04,  3.9560e-04, -5.0755e-04],\n","        [ 2.1410e-04, -4.5502e-04,  8.1401e-04, -8.8602e-04],\n","        [-1.3464e-03, -3.8104e-04,  2.9607e-04, -4.3481e-04],\n","        [-1.3981e-03, -8.2184e-04,  7.7759e-04, -6.3159e-04],\n","        [-1.9670e-03,  4.2727e-04,  5.9629e-04,  2.0029e-04],\n","        [ 8.4353e-04, -2.4995e-04,  1.1460e-03, -1.6201e-04],\n","        [ 9.2843e-05,  4.4498e-04,  5.7993e-04,  3.5891e-04],\n","        [-1.3606e-03, -4.6612e-04,  5.0278e-04, -4.8429e-04],\n","        [-2.6516e-04, -3.7624e-04,  2.5301e-04, -1.5320e-03],\n","        [ 5.3034e-04,  8.5223e-04, -5.4090e-04,  6.1376e-04],\n","        [ 7.7726e-05, -6.6903e-04, -2.8411e-04, -1.5894e-03],\n","        [ 6.4180e-04,  7.2851e-04, -6.4055e-04,  6.5596e-04],\n","        [ 7.0709e-04,  5.6685e-04,  8.0576e-04,  6.4555e-04],\n","        [ 4.5075e-04,  3.4953e-04,  6.6765e-04,  1.7347e-05],\n","        [-1.0787e-03, -2.2835e-04, -1.7168e-04,  6.3787e-06],\n","        [-1.4816e-03, -6.3704e-04,  1.1720e-04, -1.6974e-04],\n","        [ 9.5531e-04,  1.5187e-03, -7.2694e-05,  2.9236e-04],\n","        [-1.5383e-03,  3.9522e-04,  3.6218e-04,  3.5540e-04],\n","        [ 1.0704e-03,  8.4212e-04, -1.3668e-03,  6.3964e-04],\n","        [ 8.9353e-04, -1.2887e-03,  9.6962e-04, -5.4515e-04],\n","        [-3.5628e-04, -1.2462e-04,  6.5029e-05, -1.4894e-03],\n","        [ 6.4939e-04,  3.7617e-04,  1.5775e-03,  9.3740e-05],\n","        [-1.4747e-03,  3.3045e-04,  3.6762e-04,  3.5291e-04],\n","        [ 1.3973e-03,  8.2005e-04, -7.6522e-04,  6.2896e-04],\n","        [-1.4926e-04,  7.1484e-04,  8.9896e-04,  7.9630e-04],\n","        [-1.4301e-03, -7.0427e-05,  1.4273e-04, -1.8975e-04],\n","        [-1.3767e-03, -5.7281e-04,  3.3149e-04, -3.1539e-04],\n","        [ 7.3014e-04, -1.1114e-03,  9.3625e-04, -6.3436e-04],\n","        [-1.3268e-03, -6.4499e-04,  2.9693e-04, -3.5846e-04],\n","        [ 9.9530e-04,  1.1499e-03, -9.7116e-04,  7.9023e-04],\n","        [-1.5228e-03, -3.3147e-04,  5.1145e-04,  4.5484e-05],\n","        [ 1.0047e-03,  9.8398e-04, -1.1939e-03,  8.5679e-04],\n","        [-5.3035e-04, -1.3757e-04, -6.4758e-04, -1.0550e-03],\n","        [ 9.4071e-04,  1.3669e-03, -1.3424e-03,  8.9878e-04],\n","        [ 7.0616e-04,  9.8813e-04, -7.5543e-04,  7.4496e-04],\n","        [-1.3822e-03, -6.8030e-04,  4.1165e-04, -3.4589e-04],\n","        [-1.3573e-03, -4.2599e-04,  3.7730e-04, -4.6976e-04],\n","        [-1.2376e-03, -5.0811e-04,  3.8292e-04, -4.9719e-04],\n","        [-4.3992e-04, -1.6613e-04,  2.0079e-04, -1.1805e-03],\n","        [ 8.1979e-04, -1.2465e-03,  8.4310e-04, -6.4026e-04],\n","        [ 7.4144e-04,  1.2665e-03, -6.7239e-04,  9.1083e-04],\n","        [-1.4515e-03, -4.6280e-04,  1.2822e-04, -1.8005e-04],\n","        [ 1.3985e-03,  8.0573e-04, -8.0810e-04,  5.7733e-04],\n","        [ 1.1035e-03,  1.0492e-03, -5.7029e-04,  4.9235e-04],\n","        [-1.5151e-03, -6.3468e-04,  1.1159e-04, -1.7799e-04],\n","        [ 7.9983e-04,  6.0899e-04,  7.5267e-04,  5.6702e-04],\n","        [ 3.9054e-04,  3.7126e-04,  9.6406e-04,  9.0723e-06],\n","        [-1.4162e-03, -5.8013e-04,  3.2546e-04, -3.3400e-04],\n","        [ 9.7492e-04,  7.9296e-04, -6.0337e-04,  6.3254e-04],\n","        [-8.3581e-04, -1.4214e-04, -5.9512e-04, -5.3859e-04],\n","        [ 5.3937e-04, -1.6730e-04,  1.2086e-03, -8.3360e-04],\n","        [-2.8820e-04,  1.5106e-04, -6.6362e-04, -1.2898e-03],\n","        [-6.7864e-04, -2.2716e-04, -2.6976e-04, -1.0463e-03],\n","        [-1.2310e-03, -5.0631e-04,  3.8211e-04, -4.9451e-04],\n","        [-3.0824e-04, -3.2303e-04,  3.2454e-04, -1.6118e-03],\n","        [-5.0789e-04, -1.1828e-04, -6.1975e-04, -1.0532e-03],\n","        [ 4.4367e-04,  1.0666e-03, -9.1919e-05,  6.3710e-04],\n","        [ 1.3806e-03,  7.9778e-04, -7.0780e-04,  6.4174e-04],\n","        [ 2.1643e-04,  1.0128e-03,  9.5775e-06,  6.7604e-04],\n","        [-1.5469e-04, -7.1276e-04, -5.2689e-04, -1.0878e-03]])\n","Train Loss 1: 1.1601 Acc: 0.1875\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information.\n","  if __name__ == '__main__':\n"]}]},{"cell_type":"code","metadata":{"id":"zf1OiQzc9u5t"},"source":["!g++ -std=c++14 ./src/cse1.cpp ./src/cse1_param.cpp -D_NOTEBOOK -I ../../../xtensor -lcblas -o ./src/cse1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4bIvl823mZVt"},"source":["(注意) xtensorフォルダにxtensor関連のincludeを置いています。各自の環境に合わせて変更して下さい。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I31lNv_hh4s2","executionInfo":{"status":"ok","timestamp":1635254776416,"user_tz":-540,"elapsed":675,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"a59e6356-a0ee-4597-dbe6-001af5c122ba"},"source":["!./src/cse1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["### forward computation ...\n"," 1.160111\n","### backward computation ...\n","input_grad{{ 0.000388, -0.000082,  0.001442, -0.001026},\n"," {-0.00163 , -0.000588,  0.000393, -0.000363},\n"," {-0.002082, -0.001018,  0.001658, -0.000565},\n"," {-0.000511, -0.000123, -0.000648, -0.001045},\n"," { 0.000757,  0.001132, -0.000851,  0.000955},\n"," {-0.001367, -0.000591,  0.000333, -0.000317},\n"," { 0.000456,  0.001472, -0.00038 ,  0.000768},\n"," { 0.000484,  0.001022, -0.000164,  0.000845},\n"," { 0.000975, -0.000376,  0.001201,  0.000455},\n"," {-0.001371, -0.000598,  0.000337, -0.000316},\n"," { 0.001298,  0.00068 , -0.00096 ,  0.000676},\n"," { 0.000912,  0.000498, -0.000053,  0.000358},\n"," {-0.000279, -0.000499,  0.000339, -0.001631},\n"," {-0.001483,  0.000332,  0.00037 ,  0.000355},\n"," {-0.001265, -0.000566,  0.000409, -0.000314},\n"," { 0.001179,  0.000775, -0.000708,  0.000957},\n"," {-0.001308, -0.000458,  0.00041 , -0.000462},\n"," {-0.000392, -0.000395, -0.00008 , -0.001208},\n"," {-0.000253, -0.000395,  0.00061 , -0.00073 },\n"," {-0.001342, -0.000488,  0.000417, -0.000294},\n"," {-0.001888, -0.000564,  0.000313, -0.000308},\n"," { 0.000954,  0.000904, -0.001179,  0.001008},\n"," {-0.001875, -0.000513,  0.000323, -0.000292},\n"," { 0.001197, -0.000481,  0.001432, -0.00016 },\n"," {-0.000252,  0.000951,  0.000034,  0.000131},\n"," { 0.000942,  0.000537, -0.000134,  0.000346},\n"," {-0.001351, -0.000602,  0.00034 , -0.000309},\n"," {-0.0005  ,  0.000576,  0.001084,  0.000597},\n"," { 0.001154,  0.000688, -0.000999,  0.000723},\n"," {-0.001128, -0.000444,  0.000379, -0.00048 },\n"," {-0.001301, -0.00055 ,  0.000313, -0.000244},\n"," {-0.000219, -0.000649, -0.000485, -0.001153},\n"," { 0.000941,  0.001367, -0.001342,  0.000899},\n"," { 0.000485,  0.000892, -0.000115,  0.000706},\n"," { 0.000553,  0.000179, -0.001148,  0.000162},\n"," {-0.000945,  0.000009, -0.000137, -0.001615},\n"," { 0.000464,  0.001002, -0.000134,  0.000889},\n"," {-0.000229,  0.000818,  0.001241,  0.000472},\n"," {-0.001741,  0.000805,  0.00084 ,  0.000455},\n"," {-0.001092, -0.000477,  0.000311, -0.000536},\n"," {-0.000561, -0.000155, -0.000627, -0.001217},\n"," {-0.000541,  0.000075, -0.000304, -0.001565},\n"," { 0.000378,  0.000834, -0.000431,  0.000961},\n"," {-0.001458, -0.000459,  0.000125, -0.000183},\n"," { 0.000426,  0.000464,  0.000922, -0.000063},\n"," { 0.000196,  0.000857, -0.000707,  0.000899},\n"," {-0.001443,  0.000314,  0.000363,  0.000348},\n"," { 0.001253,  0.000977, -0.000619,  0.000496},\n"," { 0.000548,  0.000861, -0.000445,  0.000534},\n"," {-0.000605,  0.000158, -0.000241, -0.000767},\n"," {-0.00151 , -0.000643,  0.000116, -0.000175},\n"," { 0.001026, -0.001392,  0.000786, -0.000692},\n"," {-0.001242, -0.000497,  0.000396, -0.000508},\n"," { 0.000214, -0.000455,  0.000814, -0.000886},\n"," {-0.001346, -0.000381,  0.000296, -0.000435},\n"," {-0.001398, -0.000822,  0.000778, -0.000632},\n"," {-0.001967,  0.000427,  0.000596,  0.0002  },\n"," { 0.000844, -0.00025 ,  0.001146, -0.000162},\n"," { 0.000093,  0.000445,  0.00058 ,  0.000359},\n"," {-0.001361, -0.000466,  0.000503, -0.000484},\n"," {-0.000265, -0.000376,  0.000253, -0.001532},\n"," { 0.00053 ,  0.000852, -0.000541,  0.000614},\n"," { 0.000078, -0.000669, -0.000284, -0.001589},\n"," { 0.000642,  0.000729, -0.000641,  0.000656},\n"," { 0.000707,  0.000567,  0.000806,  0.000646},\n"," { 0.000451,  0.00035 ,  0.000668,  0.000017},\n"," {-0.001079, -0.000228, -0.000172,  0.000006},\n"," {-0.001482, -0.000637,  0.000117, -0.00017 },\n"," { 0.000955,  0.001519, -0.000073,  0.000292},\n"," {-0.001538,  0.000395,  0.000362,  0.000355},\n"," { 0.00107 ,  0.000842, -0.001367,  0.00064 },\n"," { 0.000894, -0.001289,  0.00097 , -0.000545},\n"," {-0.000356, -0.000125,  0.000065, -0.001489},\n"," { 0.000649,  0.000376,  0.001578,  0.000094},\n"," {-0.001475,  0.00033 ,  0.000368,  0.000353},\n"," { 0.001397,  0.00082 , -0.000765,  0.000629},\n"," {-0.000149,  0.000715,  0.000899,  0.000796},\n"," {-0.00143 , -0.00007 ,  0.000143, -0.00019 },\n"," {-0.001377, -0.000573,  0.000331, -0.000315},\n"," { 0.00073 , -0.001111,  0.000936, -0.000634},\n"," {-0.001327, -0.000645,  0.000297, -0.000358},\n"," { 0.000995,  0.00115 , -0.000971,  0.00079 },\n"," {-0.001523, -0.000331,  0.000511,  0.000045},\n"," { 0.001005,  0.000984, -0.001194,  0.000857},\n"," {-0.00053 , -0.000138, -0.000648, -0.001055},\n"," { 0.000941,  0.001367, -0.001342,  0.000899},\n"," { 0.000706,  0.000988, -0.000755,  0.000745},\n"," {-0.001382, -0.00068 ,  0.000412, -0.000346},\n"," {-0.001357, -0.000426,  0.000377, -0.00047 },\n"," {-0.001238, -0.000508,  0.000383, -0.000497},\n"," {-0.00044 , -0.000166,  0.000201, -0.00118 },\n"," { 0.00082 , -0.001247,  0.000843, -0.00064 },\n"," { 0.000741,  0.001267, -0.000672,  0.000911},\n"," {-0.001451, -0.000463,  0.000128, -0.00018 },\n"," { 0.001398,  0.000806, -0.000808,  0.000577},\n"," { 0.001104,  0.001049, -0.00057 ,  0.000492},\n"," {-0.001515, -0.000635,  0.000112, -0.000178},\n"," { 0.0008  ,  0.000609,  0.000753,  0.000567},\n"," { 0.000391,  0.000371,  0.000964,  0.000009},\n"," {-0.001416, -0.00058 ,  0.000325, -0.000334},\n"," { 0.000975,  0.000793, -0.000603,  0.000633},\n"," {-0.000836, -0.000142, -0.000595, -0.000539},\n"," { 0.000539, -0.000167,  0.001209, -0.000834},\n"," {-0.000288,  0.000151, -0.000664, -0.00129 },\n"," {-0.000679, -0.000227, -0.00027 , -0.001046},\n"," {-0.001231, -0.000506,  0.000382, -0.000495},\n"," {-0.000308, -0.000323,  0.000325, -0.001612},\n"," {-0.000508, -0.000118, -0.00062 , -0.001053},\n"," { 0.000444,  0.001067, -0.000092,  0.000637},\n"," { 0.001381,  0.000798, -0.000708,  0.000642},\n"," { 0.000216,  0.001013,  0.00001 ,  0.000676},\n"," {-0.000155, -0.000713, -0.000527, -0.001088}}\n"]}]},{"cell_type":"code","metadata":{"id":"-AaUeeTX6UmM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635254786019,"user_tz":-540,"elapsed":1245,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"a48c96c0-1cca-4931-eae0-dad4da73007d"},"source":["torch.manual_seed( 1 )\n","\n","#print(\"target\",target)\n","inputs.requires_grad = True\n","\n","#model = Net( labels )\n","model = Net2()\n","\n","num = inputs.size(0)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD( model.parameters(), lr=0.01 )\n","\n","num_epochs = 300\n","\n","acc = []\n","\n","for epoch in range(num_epochs):\n","  with torch.set_grad_enabled(True):\n","\n","    model.train()   # モデルを訓練モードに設定\n","\n","    outputs = model( inputs )\n","\n","    loss = criterion( outputs, labels )\n","    print(\"loss \",epoch, \" - \",loss)\n","\n","    # ラベルを予測\n","    #print(\"output\", outputs, num )\n","    _, preds = torch.max( outputs, 1 )\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    # イテレーション結果の計算\n","    epoch_loss = loss.item() * float(num)\n","\n","    # 正解数の合計を更新\n","    epoch_corrects = torch.sum( preds == labels )\n","\n","    epoch_loss = epoch_loss / float(num)\n","    epoch_acc  = epoch_corrects.double() / float(num)\n","    print('Train Loss {}: {:.4f} Acc: {:.4f} {}'.format( epoch, epoch_loss, epoch_acc, epoch_corrects ))\n","\n","    acc.append( epoch_acc )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loss  0  -  tensor(1.1601, grad_fn=<NllLossBackward>)\n","Train Loss 0: 1.1601 Acc: 0.1875 21\n","loss  1  -  tensor(1.1363, grad_fn=<NllLossBackward>)\n","Train Loss 1: 1.1363 Acc: 0.1875 21\n","loss  2  -  tensor(1.1135, grad_fn=<NllLossBackward>)\n","Train Loss 2: 1.1135 Acc: 0.1964 22\n","loss  3  -  tensor(1.0915, grad_fn=<NllLossBackward>)\n","Train Loss 3: 1.0915 Acc: 0.1786 20\n","loss  4  -  tensor(1.0704, grad_fn=<NllLossBackward>)\n","Train Loss 4: 1.0704 Acc: 0.1875 21\n","loss  5  -  tensor(1.0501, grad_fn=<NllLossBackward>)\n","Train Loss 5: 1.0501 Acc: 0.1964 22\n","loss  6  -  tensor(1.0307, grad_fn=<NllLossBackward>)\n","Train Loss 6: 1.0307 Acc: 0.1786 20\n","loss  7  -  tensor(1.0120, grad_fn=<NllLossBackward>)\n","Train Loss 7: 1.0120 Acc: 0.1875 21\n","loss  8  -  tensor(0.9941, grad_fn=<NllLossBackward>)\n","Train Loss 8: 0.9941 Acc: 0.2411 27\n","loss  9  -  tensor(0.9769, grad_fn=<NllLossBackward>)\n","Train Loss 9: 0.9769 Acc: 0.3036 34\n","loss  10  -  tensor(0.9605, grad_fn=<NllLossBackward>)\n","Train Loss 10: 0.9605 Acc: 0.3929 44\n","loss  11  -  tensor(0.9447, grad_fn=<NllLossBackward>)\n","Train Loss 11: 0.9447 Acc: 0.4554 51\n","loss  12  -  tensor(0.9296, grad_fn=<NllLossBackward>)\n","Train Loss 12: 0.9296 Acc: 0.5000 56\n","loss  13  -  tensor(0.9151, grad_fn=<NllLossBackward>)\n","Train Loss 13: 0.9151 Acc: 0.5357 60\n","loss  14  -  tensor(0.9012, grad_fn=<NllLossBackward>)\n","Train Loss 14: 0.9012 Acc: 0.6071 68\n","loss  15  -  tensor(0.8878, grad_fn=<NllLossBackward>)\n","Train Loss 15: 0.8878 Acc: 0.6250 70\n","loss  16  -  tensor(0.8750, grad_fn=<NllLossBackward>)\n","Train Loss 16: 0.8750 Acc: 0.6339 71\n","loss  17  -  tensor(0.8628, grad_fn=<NllLossBackward>)\n","Train Loss 17: 0.8628 Acc: 0.6429 72\n","loss  18  -  tensor(0.8510, grad_fn=<NllLossBackward>)\n","Train Loss 18: 0.8510 Acc: 0.6518 73\n","loss  19  -  tensor(0.8397, grad_fn=<NllLossBackward>)\n","Train Loss 19: 0.8397 Acc: 0.6607 74\n","loss  20  -  tensor(0.8288, grad_fn=<NllLossBackward>)\n","Train Loss 20: 0.8288 Acc: 0.6607 74\n","loss  21  -  tensor(0.8183, grad_fn=<NllLossBackward>)\n","Train Loss 21: 0.8183 Acc: 0.6696 75\n","loss  22  -  tensor(0.8083, grad_fn=<NllLossBackward>)\n","Train Loss 22: 0.8083 Acc: 0.6696 75\n","loss  23  -  tensor(0.7986, grad_fn=<NllLossBackward>)\n","Train Loss 23: 0.7986 Acc: 0.6696 75\n","loss  24  -  tensor(0.7894, grad_fn=<NllLossBackward>)\n","Train Loss 24: 0.7894 Acc: 0.6786 76\n","loss  25  -  tensor(0.7804, grad_fn=<NllLossBackward>)\n","Train Loss 25: 0.7804 Acc: 0.6875 77\n","loss  26  -  tensor(0.7718, grad_fn=<NllLossBackward>)\n","Train Loss 26: 0.7718 Acc: 0.6875 77\n","loss  27  -  tensor(0.7635, grad_fn=<NllLossBackward>)\n","Train Loss 27: 0.7635 Acc: 0.6875 77\n","loss  28  -  tensor(0.7555, grad_fn=<NllLossBackward>)\n","Train Loss 28: 0.7555 Acc: 0.6964 78\n","loss  29  -  tensor(0.7478, grad_fn=<NllLossBackward>)\n","Train Loss 29: 0.7478 Acc: 0.6964 78\n","loss  30  -  tensor(0.7403, grad_fn=<NllLossBackward>)\n","Train Loss 30: 0.7403 Acc: 0.6964 78\n","loss  31  -  tensor(0.7331, grad_fn=<NllLossBackward>)\n","Train Loss 31: 0.7331 Acc: 0.6964 78\n","loss  32  -  tensor(0.7261, grad_fn=<NllLossBackward>)\n","Train Loss 32: 0.7261 Acc: 0.7054 79\n","loss  33  -  tensor(0.7194, grad_fn=<NllLossBackward>)\n","Train Loss 33: 0.7194 Acc: 0.7054 79\n","loss  34  -  tensor(0.7129, grad_fn=<NllLossBackward>)\n","Train Loss 34: 0.7129 Acc: 0.7054 79\n","loss  35  -  tensor(0.7066, grad_fn=<NllLossBackward>)\n","Train Loss 35: 0.7066 Acc: 0.7054 79\n","loss  36  -  tensor(0.7005, grad_fn=<NllLossBackward>)\n","Train Loss 36: 0.7005 Acc: 0.7054 79\n","loss  37  -  tensor(0.6946, grad_fn=<NllLossBackward>)\n","Train Loss 37: 0.6946 Acc: 0.7054 79\n","loss  38  -  tensor(0.6888, grad_fn=<NllLossBackward>)\n","Train Loss 38: 0.6888 Acc: 0.7054 79\n","loss  39  -  tensor(0.6833, grad_fn=<NllLossBackward>)\n","Train Loss 39: 0.6833 Acc: 0.7054 79\n","loss  40  -  tensor(0.6778, grad_fn=<NllLossBackward>)\n","Train Loss 40: 0.6778 Acc: 0.7143 80\n","loss  41  -  tensor(0.6726, grad_fn=<NllLossBackward>)\n","Train Loss 41: 0.6726 Acc: 0.7143 80\n","loss  42  -  tensor(0.6675, grad_fn=<NllLossBackward>)\n","Train Loss 42: 0.6675 Acc: 0.7232 81\n","loss  43  -  tensor(0.6625, grad_fn=<NllLossBackward>)\n","Train Loss 43: 0.6625 Acc: 0.7232 81\n","loss  44  -  tensor(0.6577, grad_fn=<NllLossBackward>)\n","Train Loss 44: 0.6577 Acc: 0.7232 81\n","loss  45  -  tensor(0.6530, grad_fn=<NllLossBackward>)\n","Train Loss 45: 0.6530 Acc: 0.7321 82\n","loss  46  -  tensor(0.6484, grad_fn=<NllLossBackward>)\n","Train Loss 46: 0.6484 Acc: 0.7321 82\n","loss  47  -  tensor(0.6439, grad_fn=<NllLossBackward>)\n","Train Loss 47: 0.6439 Acc: 0.7321 82\n","loss  48  -  tensor(0.6396, grad_fn=<NllLossBackward>)\n","Train Loss 48: 0.6396 Acc: 0.7411 83\n","loss  49  -  tensor(0.6354, grad_fn=<NllLossBackward>)\n","Train Loss 49: 0.6354 Acc: 0.7411 83\n","loss  50  -  tensor(0.6312, grad_fn=<NllLossBackward>)\n","Train Loss 50: 0.6312 Acc: 0.7411 83\n","loss  51  -  tensor(0.6272, grad_fn=<NllLossBackward>)\n","Train Loss 51: 0.6272 Acc: 0.7411 83\n","loss  52  -  tensor(0.6232, grad_fn=<NllLossBackward>)\n","Train Loss 52: 0.6232 Acc: 0.7411 83\n","loss  53  -  tensor(0.6194, grad_fn=<NllLossBackward>)\n","Train Loss 53: 0.6194 Acc: 0.7411 83\n","loss  54  -  tensor(0.6156, grad_fn=<NllLossBackward>)\n","Train Loss 54: 0.6156 Acc: 0.7411 83\n","loss  55  -  tensor(0.6119, grad_fn=<NllLossBackward>)\n","Train Loss 55: 0.6119 Acc: 0.7411 83\n","loss  56  -  tensor(0.6083, grad_fn=<NllLossBackward>)\n","Train Loss 56: 0.6083 Acc: 0.7500 84\n","loss  57  -  tensor(0.6048, grad_fn=<NllLossBackward>)\n","Train Loss 57: 0.6048 Acc: 0.7500 84\n","loss  58  -  tensor(0.6013, grad_fn=<NllLossBackward>)\n","Train Loss 58: 0.6013 Acc: 0.7500 84\n","loss  59  -  tensor(0.5980, grad_fn=<NllLossBackward>)\n","Train Loss 59: 0.5980 Acc: 0.7500 84\n","loss  60  -  tensor(0.5946, grad_fn=<NllLossBackward>)\n","Train Loss 60: 0.5946 Acc: 0.7500 84\n","loss  61  -  tensor(0.5914, grad_fn=<NllLossBackward>)\n","Train Loss 61: 0.5914 Acc: 0.7500 84\n","loss  62  -  tensor(0.5882, grad_fn=<NllLossBackward>)\n","Train Loss 62: 0.5882 Acc: 0.7500 84\n","loss  63  -  tensor(0.5851, grad_fn=<NllLossBackward>)\n","Train Loss 63: 0.5851 Acc: 0.7589 85\n","loss  64  -  tensor(0.5820, grad_fn=<NllLossBackward>)\n","Train Loss 64: 0.5820 Acc: 0.7589 85\n","loss  65  -  tensor(0.5790, grad_fn=<NllLossBackward>)\n","Train Loss 65: 0.5790 Acc: 0.7589 85\n","loss  66  -  tensor(0.5761, grad_fn=<NllLossBackward>)\n","Train Loss 66: 0.5761 Acc: 0.7589 85\n","loss  67  -  tensor(0.5732, grad_fn=<NllLossBackward>)\n","Train Loss 67: 0.5732 Acc: 0.7679 86\n","loss  68  -  tensor(0.5703, grad_fn=<NllLossBackward>)\n","Train Loss 68: 0.5703 Acc: 0.7679 86\n","loss  69  -  tensor(0.5675, grad_fn=<NllLossBackward>)\n","Train Loss 69: 0.5675 Acc: 0.7679 86\n","loss  70  -  tensor(0.5648, grad_fn=<NllLossBackward>)\n","Train Loss 70: 0.5648 Acc: 0.7768 87\n","loss  71  -  tensor(0.5621, grad_fn=<NllLossBackward>)\n","Train Loss 71: 0.5621 Acc: 0.7768 87\n","loss  72  -  tensor(0.5594, grad_fn=<NllLossBackward>)\n","Train Loss 72: 0.5594 Acc: 0.7857 88\n","loss  73  -  tensor(0.5568, grad_fn=<NllLossBackward>)\n","Train Loss 73: 0.5568 Acc: 0.7857 88\n","loss  74  -  tensor(0.5543, grad_fn=<NllLossBackward>)\n","Train Loss 74: 0.5543 Acc: 0.7857 88\n","loss  75  -  tensor(0.5517, grad_fn=<NllLossBackward>)\n","Train Loss 75: 0.5517 Acc: 0.7857 88\n","loss  76  -  tensor(0.5492, grad_fn=<NllLossBackward>)\n","Train Loss 76: 0.5492 Acc: 0.7857 88\n","loss  77  -  tensor(0.5468, grad_fn=<NllLossBackward>)\n","Train Loss 77: 0.5468 Acc: 0.7857 88\n","loss  78  -  tensor(0.5444, grad_fn=<NllLossBackward>)\n","Train Loss 78: 0.5444 Acc: 0.7857 88\n","loss  79  -  tensor(0.5420, grad_fn=<NllLossBackward>)\n","Train Loss 79: 0.5420 Acc: 0.7857 88\n","loss  80  -  tensor(0.5397, grad_fn=<NllLossBackward>)\n","Train Loss 80: 0.5397 Acc: 0.7857 88\n","loss  81  -  tensor(0.5374, grad_fn=<NllLossBackward>)\n","Train Loss 81: 0.5374 Acc: 0.7857 88\n","loss  82  -  tensor(0.5351, grad_fn=<NllLossBackward>)\n","Train Loss 82: 0.5351 Acc: 0.7946 89\n","loss  83  -  tensor(0.5329, grad_fn=<NllLossBackward>)\n","Train Loss 83: 0.5329 Acc: 0.7946 89\n","loss  84  -  tensor(0.5307, grad_fn=<NllLossBackward>)\n","Train Loss 84: 0.5307 Acc: 0.7946 89\n","loss  85  -  tensor(0.5285, grad_fn=<NllLossBackward>)\n","Train Loss 85: 0.5285 Acc: 0.7857 88\n","loss  86  -  tensor(0.5263, grad_fn=<NllLossBackward>)\n","Train Loss 86: 0.5263 Acc: 0.7857 88\n","loss  87  -  tensor(0.5242, grad_fn=<NllLossBackward>)\n","Train Loss 87: 0.5242 Acc: 0.7857 88\n","loss  88  -  tensor(0.5221, grad_fn=<NllLossBackward>)\n","Train Loss 88: 0.5221 Acc: 0.7857 88\n","loss  89  -  tensor(0.5201, grad_fn=<NllLossBackward>)\n","Train Loss 89: 0.5201 Acc: 0.7857 88\n","loss  90  -  tensor(0.5181, grad_fn=<NllLossBackward>)\n","Train Loss 90: 0.5181 Acc: 0.7857 88\n","loss  91  -  tensor(0.5160, grad_fn=<NllLossBackward>)\n","Train Loss 91: 0.5160 Acc: 0.7857 88\n","loss  92  -  tensor(0.5141, grad_fn=<NllLossBackward>)\n","Train Loss 92: 0.5141 Acc: 0.7946 89\n","loss  93  -  tensor(0.5121, grad_fn=<NllLossBackward>)\n","Train Loss 93: 0.5121 Acc: 0.8036 90\n","loss  94  -  tensor(0.5102, grad_fn=<NllLossBackward>)\n","Train Loss 94: 0.5102 Acc: 0.8036 90\n","loss  95  -  tensor(0.5083, grad_fn=<NllLossBackward>)\n","Train Loss 95: 0.5083 Acc: 0.8036 90\n","loss  96  -  tensor(0.5064, grad_fn=<NllLossBackward>)\n","Train Loss 96: 0.5064 Acc: 0.8036 90\n","loss  97  -  tensor(0.5046, grad_fn=<NllLossBackward>)\n","Train Loss 97: 0.5046 Acc: 0.8036 90\n","loss  98  -  tensor(0.5027, grad_fn=<NllLossBackward>)\n","Train Loss 98: 0.5027 Acc: 0.8036 90\n","loss  99  -  tensor(0.5009, grad_fn=<NllLossBackward>)\n","Train Loss 99: 0.5009 Acc: 0.8036 90\n","loss  100  -  tensor(0.4991, grad_fn=<NllLossBackward>)\n","Train Loss 100: 0.4991 Acc: 0.8036 90\n","loss  101  -  tensor(0.4974, grad_fn=<NllLossBackward>)\n","Train Loss 101: 0.4974 Acc: 0.8036 90\n","loss  102  -  tensor(0.4956, grad_fn=<NllLossBackward>)\n","Train Loss 102: 0.4956 Acc: 0.8036 90\n","loss  103  -  tensor(0.4939, grad_fn=<NllLossBackward>)\n","Train Loss 103: 0.4939 Acc: 0.8036 90\n","loss  104  -  tensor(0.4922, grad_fn=<NllLossBackward>)\n","Train Loss 104: 0.4922 Acc: 0.8036 90\n","loss  105  -  tensor(0.4905, grad_fn=<NllLossBackward>)\n","Train Loss 105: 0.4905 Acc: 0.8036 90\n","loss  106  -  tensor(0.4888, grad_fn=<NllLossBackward>)\n","Train Loss 106: 0.4888 Acc: 0.8036 90\n","loss  107  -  tensor(0.4872, grad_fn=<NllLossBackward>)\n","Train Loss 107: 0.4872 Acc: 0.8036 90\n","loss  108  -  tensor(0.4855, grad_fn=<NllLossBackward>)\n","Train Loss 108: 0.4855 Acc: 0.8036 90\n","loss  109  -  tensor(0.4839, grad_fn=<NllLossBackward>)\n","Train Loss 109: 0.4839 Acc: 0.8036 90\n","loss  110  -  tensor(0.4823, grad_fn=<NllLossBackward>)\n","Train Loss 110: 0.4823 Acc: 0.8036 90\n","loss  111  -  tensor(0.4807, grad_fn=<NllLossBackward>)\n","Train Loss 111: 0.4807 Acc: 0.8036 90\n","loss  112  -  tensor(0.4792, grad_fn=<NllLossBackward>)\n","Train Loss 112: 0.4792 Acc: 0.8036 90\n","loss  113  -  tensor(0.4776, grad_fn=<NllLossBackward>)\n","Train Loss 113: 0.4776 Acc: 0.8036 90\n","loss  114  -  tensor(0.4761, grad_fn=<NllLossBackward>)\n","Train Loss 114: 0.4761 Acc: 0.8036 90\n","loss  115  -  tensor(0.4746, grad_fn=<NllLossBackward>)\n","Train Loss 115: 0.4746 Acc: 0.8214 92\n","loss  116  -  tensor(0.4731, grad_fn=<NllLossBackward>)\n","Train Loss 116: 0.4731 Acc: 0.8304 93\n","loss  117  -  tensor(0.4716, grad_fn=<NllLossBackward>)\n","Train Loss 117: 0.4716 Acc: 0.8304 93\n","loss  118  -  tensor(0.4701, grad_fn=<NllLossBackward>)\n","Train Loss 118: 0.4701 Acc: 0.8393 94\n","loss  119  -  tensor(0.4687, grad_fn=<NllLossBackward>)\n","Train Loss 119: 0.4687 Acc: 0.8393 94\n","loss  120  -  tensor(0.4673, grad_fn=<NllLossBackward>)\n","Train Loss 120: 0.4673 Acc: 0.8393 94\n","loss  121  -  tensor(0.4658, grad_fn=<NllLossBackward>)\n","Train Loss 121: 0.4658 Acc: 0.8393 94\n","loss  122  -  tensor(0.4644, grad_fn=<NllLossBackward>)\n","Train Loss 122: 0.4644 Acc: 0.8393 94\n","loss  123  -  tensor(0.4630, grad_fn=<NllLossBackward>)\n","Train Loss 123: 0.4630 Acc: 0.8393 94\n","loss  124  -  tensor(0.4616, grad_fn=<NllLossBackward>)\n","Train Loss 124: 0.4616 Acc: 0.8393 94\n","loss  125  -  tensor(0.4603, grad_fn=<NllLossBackward>)\n","Train Loss 125: 0.4603 Acc: 0.8393 94\n","loss  126  -  tensor(0.4589, grad_fn=<NllLossBackward>)\n","Train Loss 126: 0.4589 Acc: 0.8393 94\n","loss  127  -  tensor(0.4576, grad_fn=<NllLossBackward>)\n","Train Loss 127: 0.4576 Acc: 0.8571 96\n","loss  128  -  tensor(0.4562, grad_fn=<NllLossBackward>)\n","Train Loss 128: 0.4562 Acc: 0.8571 96\n","loss  129  -  tensor(0.4549, grad_fn=<NllLossBackward>)\n","Train Loss 129: 0.4549 Acc: 0.8571 96\n","loss  130  -  tensor(0.4536, grad_fn=<NllLossBackward>)\n","Train Loss 130: 0.4536 Acc: 0.8571 96\n","loss  131  -  tensor(0.4523, grad_fn=<NllLossBackward>)\n","Train Loss 131: 0.4523 Acc: 0.8571 96\n","loss  132  -  tensor(0.4511, grad_fn=<NllLossBackward>)\n","Train Loss 132: 0.4511 Acc: 0.8571 96\n","loss  133  -  tensor(0.4498, grad_fn=<NllLossBackward>)\n","Train Loss 133: 0.4498 Acc: 0.8571 96\n","loss  134  -  tensor(0.4485, grad_fn=<NllLossBackward>)\n","Train Loss 134: 0.4485 Acc: 0.8571 96\n","loss  135  -  tensor(0.4473, grad_fn=<NllLossBackward>)\n","Train Loss 135: 0.4473 Acc: 0.8571 96\n","loss  136  -  tensor(0.4460, grad_fn=<NllLossBackward>)\n","Train Loss 136: 0.4460 Acc: 0.8571 96\n","loss  137  -  tensor(0.4448, grad_fn=<NllLossBackward>)\n","Train Loss 137: 0.4448 Acc: 0.8571 96\n","loss  138  -  tensor(0.4436, grad_fn=<NllLossBackward>)\n","Train Loss 138: 0.4436 Acc: 0.8571 96\n","loss  139  -  tensor(0.4424, grad_fn=<NllLossBackward>)\n","Train Loss 139: 0.4424 Acc: 0.8571 96\n","loss  140  -  tensor(0.4412, grad_fn=<NllLossBackward>)\n","Train Loss 140: 0.4412 Acc: 0.8571 96\n","loss  141  -  tensor(0.4400, grad_fn=<NllLossBackward>)\n","Train Loss 141: 0.4400 Acc: 0.8571 96\n","loss  142  -  tensor(0.4388, grad_fn=<NllLossBackward>)\n","Train Loss 142: 0.4388 Acc: 0.8571 96\n","loss  143  -  tensor(0.4377, grad_fn=<NllLossBackward>)\n","Train Loss 143: 0.4377 Acc: 0.8571 96\n","loss  144  -  tensor(0.4365, grad_fn=<NllLossBackward>)\n","Train Loss 144: 0.4365 Acc: 0.8571 96\n","loss  145  -  tensor(0.4354, grad_fn=<NllLossBackward>)\n","Train Loss 145: 0.4354 Acc: 0.8571 96\n","loss  146  -  tensor(0.4343, grad_fn=<NllLossBackward>)\n","Train Loss 146: 0.4343 Acc: 0.8661 97\n","loss  147  -  tensor(0.4331, grad_fn=<NllLossBackward>)\n","Train Loss 147: 0.4331 Acc: 0.8661 97\n","loss  148  -  tensor(0.4320, grad_fn=<NllLossBackward>)\n","Train Loss 148: 0.4320 Acc: 0.8661 97\n","loss  149  -  tensor(0.4309, grad_fn=<NllLossBackward>)\n","Train Loss 149: 0.4309 Acc: 0.8661 97\n","loss  150  -  tensor(0.4298, grad_fn=<NllLossBackward>)\n","Train Loss 150: 0.4298 Acc: 0.8661 97\n","loss  151  -  tensor(0.4287, grad_fn=<NllLossBackward>)\n","Train Loss 151: 0.4287 Acc: 0.8661 97\n","loss  152  -  tensor(0.4276, grad_fn=<NllLossBackward>)\n","Train Loss 152: 0.4276 Acc: 0.8661 97\n","loss  153  -  tensor(0.4266, grad_fn=<NllLossBackward>)\n","Train Loss 153: 0.4266 Acc: 0.8661 97\n","loss  154  -  tensor(0.4255, grad_fn=<NllLossBackward>)\n","Train Loss 154: 0.4255 Acc: 0.8661 97\n","loss  155  -  tensor(0.4245, grad_fn=<NllLossBackward>)\n","Train Loss 155: 0.4245 Acc: 0.8661 97\n","loss  156  -  tensor(0.4234, grad_fn=<NllLossBackward>)\n","Train Loss 156: 0.4234 Acc: 0.8661 97\n","loss  157  -  tensor(0.4224, grad_fn=<NllLossBackward>)\n","Train Loss 157: 0.4224 Acc: 0.8661 97\n","loss  158  -  tensor(0.4214, grad_fn=<NllLossBackward>)\n","Train Loss 158: 0.4214 Acc: 0.8661 97\n","loss  159  -  tensor(0.4203, grad_fn=<NllLossBackward>)\n","Train Loss 159: 0.4203 Acc: 0.8661 97\n","loss  160  -  tensor(0.4193, grad_fn=<NllLossBackward>)\n","Train Loss 160: 0.4193 Acc: 0.8661 97\n","loss  161  -  tensor(0.4183, grad_fn=<NllLossBackward>)\n","Train Loss 161: 0.4183 Acc: 0.8661 97\n","loss  162  -  tensor(0.4173, grad_fn=<NllLossBackward>)\n","Train Loss 162: 0.4173 Acc: 0.8661 97\n","loss  163  -  tensor(0.4163, grad_fn=<NllLossBackward>)\n","Train Loss 163: 0.4163 Acc: 0.8661 97\n","loss  164  -  tensor(0.4153, grad_fn=<NllLossBackward>)\n","Train Loss 164: 0.4153 Acc: 0.8661 97\n","loss  165  -  tensor(0.4144, grad_fn=<NllLossBackward>)\n","Train Loss 165: 0.4144 Acc: 0.8750 98\n","loss  166  -  tensor(0.4134, grad_fn=<NllLossBackward>)\n","Train Loss 166: 0.4134 Acc: 0.8750 98\n","loss  167  -  tensor(0.4124, grad_fn=<NllLossBackward>)\n","Train Loss 167: 0.4124 Acc: 0.8750 98\n","loss  168  -  tensor(0.4115, grad_fn=<NllLossBackward>)\n","Train Loss 168: 0.4115 Acc: 0.8750 98\n","loss  169  -  tensor(0.4105, grad_fn=<NllLossBackward>)\n","Train Loss 169: 0.4105 Acc: 0.8750 98\n","loss  170  -  tensor(0.4096, grad_fn=<NllLossBackward>)\n","Train Loss 170: 0.4096 Acc: 0.8750 98\n","loss  171  -  tensor(0.4087, grad_fn=<NllLossBackward>)\n","Train Loss 171: 0.4087 Acc: 0.8750 98\n","loss  172  -  tensor(0.4077, grad_fn=<NllLossBackward>)\n","Train Loss 172: 0.4077 Acc: 0.8750 98\n","loss  173  -  tensor(0.4068, grad_fn=<NllLossBackward>)\n","Train Loss 173: 0.4068 Acc: 0.8750 98\n","loss  174  -  tensor(0.4059, grad_fn=<NllLossBackward>)\n","Train Loss 174: 0.4059 Acc: 0.8750 98\n","loss  175  -  tensor(0.4050, grad_fn=<NllLossBackward>)\n","Train Loss 175: 0.4050 Acc: 0.8750 98\n","loss  176  -  tensor(0.4041, grad_fn=<NllLossBackward>)\n","Train Loss 176: 0.4041 Acc: 0.8750 98\n","loss  177  -  tensor(0.4032, grad_fn=<NllLossBackward>)\n","Train Loss 177: 0.4032 Acc: 0.8750 98\n","loss  178  -  tensor(0.4023, grad_fn=<NllLossBackward>)\n","Train Loss 178: 0.4023 Acc: 0.8750 98\n","loss  179  -  tensor(0.4015, grad_fn=<NllLossBackward>)\n","Train Loss 179: 0.4015 Acc: 0.8750 98\n","loss  180  -  tensor(0.4006, grad_fn=<NllLossBackward>)\n","Train Loss 180: 0.4006 Acc: 0.8839 99\n","loss  181  -  tensor(0.3997, grad_fn=<NllLossBackward>)\n","Train Loss 181: 0.3997 Acc: 0.8839 99\n","loss  182  -  tensor(0.3988, grad_fn=<NllLossBackward>)\n","Train Loss 182: 0.3988 Acc: 0.8839 99\n","loss  183  -  tensor(0.3980, grad_fn=<NllLossBackward>)\n","Train Loss 183: 0.3980 Acc: 0.8839 99\n","loss  184  -  tensor(0.3971, grad_fn=<NllLossBackward>)\n","Train Loss 184: 0.3971 Acc: 0.8839 99\n","loss  185  -  tensor(0.3963, grad_fn=<NllLossBackward>)\n","Train Loss 185: 0.3963 Acc: 0.8839 99\n","loss  186  -  tensor(0.3955, grad_fn=<NllLossBackward>)\n","Train Loss 186: 0.3955 Acc: 0.8839 99\n","loss  187  -  tensor(0.3946, grad_fn=<NllLossBackward>)\n","Train Loss 187: 0.3946 Acc: 0.8839 99\n","loss  188  -  tensor(0.3938, grad_fn=<NllLossBackward>)\n","Train Loss 188: 0.3938 Acc: 0.8839 99\n","loss  189  -  tensor(0.3930, grad_fn=<NllLossBackward>)\n","Train Loss 189: 0.3930 Acc: 0.8839 99\n","loss  190  -  tensor(0.3922, grad_fn=<NllLossBackward>)\n","Train Loss 190: 0.3922 Acc: 0.8839 99\n","loss  191  -  tensor(0.3914, grad_fn=<NllLossBackward>)\n","Train Loss 191: 0.3914 Acc: 0.8839 99\n","loss  192  -  tensor(0.3905, grad_fn=<NllLossBackward>)\n","Train Loss 192: 0.3905 Acc: 0.8839 99\n","loss  193  -  tensor(0.3897, grad_fn=<NllLossBackward>)\n","Train Loss 193: 0.3897 Acc: 0.8839 99\n","loss  194  -  tensor(0.3890, grad_fn=<NllLossBackward>)\n","Train Loss 194: 0.3890 Acc: 0.8839 99\n","loss  195  -  tensor(0.3882, grad_fn=<NllLossBackward>)\n","Train Loss 195: 0.3882 Acc: 0.8839 99\n","loss  196  -  tensor(0.3874, grad_fn=<NllLossBackward>)\n","Train Loss 196: 0.3874 Acc: 0.8929 100\n","loss  197  -  tensor(0.3866, grad_fn=<NllLossBackward>)\n","Train Loss 197: 0.3866 Acc: 0.8929 100\n","loss  198  -  tensor(0.3858, grad_fn=<NllLossBackward>)\n","Train Loss 198: 0.3858 Acc: 0.8929 100\n","loss  199  -  tensor(0.3851, grad_fn=<NllLossBackward>)\n","Train Loss 199: 0.3851 Acc: 0.8929 100\n","loss  200  -  tensor(0.3843, grad_fn=<NllLossBackward>)\n","Train Loss 200: 0.3843 Acc: 0.8929 100\n","loss  201  -  tensor(0.3835, grad_fn=<NllLossBackward>)\n","Train Loss 201: 0.3835 Acc: 0.8929 100\n","loss  202  -  tensor(0.3828, grad_fn=<NllLossBackward>)\n","Train Loss 202: 0.3828 Acc: 0.8929 100\n","loss  203  -  tensor(0.3820, grad_fn=<NllLossBackward>)\n","Train Loss 203: 0.3820 Acc: 0.8929 100\n","loss  204  -  tensor(0.3813, grad_fn=<NllLossBackward>)\n","Train Loss 204: 0.3813 Acc: 0.8929 100\n","loss  205  -  tensor(0.3805, grad_fn=<NllLossBackward>)\n","Train Loss 205: 0.3805 Acc: 0.8929 100\n","loss  206  -  tensor(0.3798, grad_fn=<NllLossBackward>)\n","Train Loss 206: 0.3798 Acc: 0.8929 100\n","loss  207  -  tensor(0.3791, grad_fn=<NllLossBackward>)\n","Train Loss 207: 0.3791 Acc: 0.8929 100\n","loss  208  -  tensor(0.3783, grad_fn=<NllLossBackward>)\n","Train Loss 208: 0.3783 Acc: 0.8929 100\n","loss  209  -  tensor(0.3776, grad_fn=<NllLossBackward>)\n","Train Loss 209: 0.3776 Acc: 0.8929 100\n","loss  210  -  tensor(0.3769, grad_fn=<NllLossBackward>)\n","Train Loss 210: 0.3769 Acc: 0.8929 100\n","loss  211  -  tensor(0.3762, grad_fn=<NllLossBackward>)\n","Train Loss 211: 0.3762 Acc: 0.8929 100\n","loss  212  -  tensor(0.3755, grad_fn=<NllLossBackward>)\n","Train Loss 212: 0.3755 Acc: 0.8929 100\n","loss  213  -  tensor(0.3747, grad_fn=<NllLossBackward>)\n","Train Loss 213: 0.3747 Acc: 0.8929 100\n","loss  214  -  tensor(0.3740, grad_fn=<NllLossBackward>)\n","Train Loss 214: 0.3740 Acc: 0.8929 100\n","loss  215  -  tensor(0.3733, grad_fn=<NllLossBackward>)\n","Train Loss 215: 0.3733 Acc: 0.8929 100\n","loss  216  -  tensor(0.3727, grad_fn=<NllLossBackward>)\n","Train Loss 216: 0.3727 Acc: 0.8929 100\n","loss  217  -  tensor(0.3720, grad_fn=<NllLossBackward>)\n","Train Loss 217: 0.3720 Acc: 0.8929 100\n","loss  218  -  tensor(0.3713, grad_fn=<NllLossBackward>)\n","Train Loss 218: 0.3713 Acc: 0.9018 101\n","loss  219  -  tensor(0.3706, grad_fn=<NllLossBackward>)\n","Train Loss 219: 0.3706 Acc: 0.9018 101\n","loss  220  -  tensor(0.3699, grad_fn=<NllLossBackward>)\n","Train Loss 220: 0.3699 Acc: 0.9018 101\n","loss  221  -  tensor(0.3692, grad_fn=<NllLossBackward>)\n","Train Loss 221: 0.3692 Acc: 0.9018 101\n","loss  222  -  tensor(0.3686, grad_fn=<NllLossBackward>)\n","Train Loss 222: 0.3686 Acc: 0.9018 101\n","loss  223  -  tensor(0.3679, grad_fn=<NllLossBackward>)\n","Train Loss 223: 0.3679 Acc: 0.9018 101\n","loss  224  -  tensor(0.3672, grad_fn=<NllLossBackward>)\n","Train Loss 224: 0.3672 Acc: 0.9018 101\n","loss  225  -  tensor(0.3666, grad_fn=<NllLossBackward>)\n","Train Loss 225: 0.3666 Acc: 0.9018 101\n","loss  226  -  tensor(0.3659, grad_fn=<NllLossBackward>)\n","Train Loss 226: 0.3659 Acc: 0.9018 101\n","loss  227  -  tensor(0.3653, grad_fn=<NllLossBackward>)\n","Train Loss 227: 0.3653 Acc: 0.9107 102\n","loss  228  -  tensor(0.3646, grad_fn=<NllLossBackward>)\n","Train Loss 228: 0.3646 Acc: 0.9107 102\n","loss  229  -  tensor(0.3640, grad_fn=<NllLossBackward>)\n","Train Loss 229: 0.3640 Acc: 0.9107 102\n","loss  230  -  tensor(0.3633, grad_fn=<NllLossBackward>)\n","Train Loss 230: 0.3633 Acc: 0.9107 102\n","loss  231  -  tensor(0.3627, grad_fn=<NllLossBackward>)\n","Train Loss 231: 0.3627 Acc: 0.9107 102\n","loss  232  -  tensor(0.3620, grad_fn=<NllLossBackward>)\n","Train Loss 232: 0.3620 Acc: 0.9107 102\n","loss  233  -  tensor(0.3614, grad_fn=<NllLossBackward>)\n","Train Loss 233: 0.3614 Acc: 0.9107 102\n","loss  234  -  tensor(0.3608, grad_fn=<NllLossBackward>)\n","Train Loss 234: 0.3608 Acc: 0.9107 102\n","loss  235  -  tensor(0.3602, grad_fn=<NllLossBackward>)\n","Train Loss 235: 0.3602 Acc: 0.9196 103\n","loss  236  -  tensor(0.3595, grad_fn=<NllLossBackward>)\n","Train Loss 236: 0.3595 Acc: 0.9196 103\n","loss  237  -  tensor(0.3589, grad_fn=<NllLossBackward>)\n","Train Loss 237: 0.3589 Acc: 0.9196 103\n","loss  238  -  tensor(0.3583, grad_fn=<NllLossBackward>)\n","Train Loss 238: 0.3583 Acc: 0.9196 103\n","loss  239  -  tensor(0.3577, grad_fn=<NllLossBackward>)\n","Train Loss 239: 0.3577 Acc: 0.9196 103\n","loss  240  -  tensor(0.3571, grad_fn=<NllLossBackward>)\n","Train Loss 240: 0.3571 Acc: 0.9196 103\n","loss  241  -  tensor(0.3565, grad_fn=<NllLossBackward>)\n","Train Loss 241: 0.3565 Acc: 0.9196 103\n","loss  242  -  tensor(0.3559, grad_fn=<NllLossBackward>)\n","Train Loss 242: 0.3559 Acc: 0.9196 103\n","loss  243  -  tensor(0.3553, grad_fn=<NllLossBackward>)\n","Train Loss 243: 0.3553 Acc: 0.9196 103\n","loss  244  -  tensor(0.3547, grad_fn=<NllLossBackward>)\n","Train Loss 244: 0.3547 Acc: 0.9196 103\n","loss  245  -  tensor(0.3541, grad_fn=<NllLossBackward>)\n","Train Loss 245: 0.3541 Acc: 0.9196 103\n","loss  246  -  tensor(0.3535, grad_fn=<NllLossBackward>)\n","Train Loss 246: 0.3535 Acc: 0.9196 103\n","loss  247  -  tensor(0.3529, grad_fn=<NllLossBackward>)\n","Train Loss 247: 0.3529 Acc: 0.9196 103\n","loss  248  -  tensor(0.3523, grad_fn=<NllLossBackward>)\n","Train Loss 248: 0.3523 Acc: 0.9196 103\n","loss  249  -  tensor(0.3517, grad_fn=<NllLossBackward>)\n","Train Loss 249: 0.3517 Acc: 0.9196 103\n","loss  250  -  tensor(0.3512, grad_fn=<NllLossBackward>)\n","Train Loss 250: 0.3512 Acc: 0.9196 103\n","loss  251  -  tensor(0.3506, grad_fn=<NllLossBackward>)\n","Train Loss 251: 0.3506 Acc: 0.9196 103\n","loss  252  -  tensor(0.3500, grad_fn=<NllLossBackward>)\n","Train Loss 252: 0.3500 Acc: 0.9196 103\n","loss  253  -  tensor(0.3494, grad_fn=<NllLossBackward>)\n","Train Loss 253: 0.3494 Acc: 0.9196 103\n","loss  254  -  tensor(0.3489, grad_fn=<NllLossBackward>)\n","Train Loss 254: 0.3489 Acc: 0.9196 103\n","loss  255  -  tensor(0.3483, grad_fn=<NllLossBackward>)\n","Train Loss 255: 0.3483 Acc: 0.9196 103\n","loss  256  -  tensor(0.3478, grad_fn=<NllLossBackward>)\n","Train Loss 256: 0.3478 Acc: 0.9196 103\n","loss  257  -  tensor(0.3472, grad_fn=<NllLossBackward>)\n","Train Loss 257: 0.3472 Acc: 0.9196 103\n","loss  258  -  tensor(0.3466, grad_fn=<NllLossBackward>)\n","Train Loss 258: 0.3466 Acc: 0.9196 103\n","loss  259  -  tensor(0.3461, grad_fn=<NllLossBackward>)\n","Train Loss 259: 0.3461 Acc: 0.9196 103\n","loss  260  -  tensor(0.3455, grad_fn=<NllLossBackward>)\n","Train Loss 260: 0.3455 Acc: 0.9196 103\n","loss  261  -  tensor(0.3450, grad_fn=<NllLossBackward>)\n","Train Loss 261: 0.3450 Acc: 0.9196 103\n","loss  262  -  tensor(0.3444, grad_fn=<NllLossBackward>)\n","Train Loss 262: 0.3444 Acc: 0.9196 103\n","loss  263  -  tensor(0.3439, grad_fn=<NllLossBackward>)\n","Train Loss 263: 0.3439 Acc: 0.9196 103\n","loss  264  -  tensor(0.3434, grad_fn=<NllLossBackward>)\n","Train Loss 264: 0.3434 Acc: 0.9196 103\n","loss  265  -  tensor(0.3428, grad_fn=<NllLossBackward>)\n","Train Loss 265: 0.3428 Acc: 0.9196 103\n","loss  266  -  tensor(0.3423, grad_fn=<NllLossBackward>)\n","Train Loss 266: 0.3423 Acc: 0.9196 103\n","loss  267  -  tensor(0.3417, grad_fn=<NllLossBackward>)\n","Train Loss 267: 0.3417 Acc: 0.9196 103\n","loss  268  -  tensor(0.3412, grad_fn=<NllLossBackward>)\n","Train Loss 268: 0.3412 Acc: 0.9196 103\n","loss  269  -  tensor(0.3407, grad_fn=<NllLossBackward>)\n","Train Loss 269: 0.3407 Acc: 0.9196 103\n","loss  270  -  tensor(0.3402, grad_fn=<NllLossBackward>)\n","Train Loss 270: 0.3402 Acc: 0.9196 103\n","loss  271  -  tensor(0.3396, grad_fn=<NllLossBackward>)\n","Train Loss 271: 0.3396 Acc: 0.9196 103\n","loss  272  -  tensor(0.3391, grad_fn=<NllLossBackward>)\n","Train Loss 272: 0.3391 Acc: 0.9196 103\n","loss  273  -  tensor(0.3386, grad_fn=<NllLossBackward>)\n","Train Loss 273: 0.3386 Acc: 0.9196 103\n","loss  274  -  tensor(0.3381, grad_fn=<NllLossBackward>)\n","Train Loss 274: 0.3381 Acc: 0.9196 103\n","loss  275  -  tensor(0.3376, grad_fn=<NllLossBackward>)\n","Train Loss 275: 0.3376 Acc: 0.9196 103\n","loss  276  -  tensor(0.3370, grad_fn=<NllLossBackward>)\n","Train Loss 276: 0.3370 Acc: 0.9196 103\n","loss  277  -  tensor(0.3365, grad_fn=<NllLossBackward>)\n","Train Loss 277: 0.3365 Acc: 0.9196 103\n","loss  278  -  tensor(0.3360, grad_fn=<NllLossBackward>)\n","Train Loss 278: 0.3360 Acc: 0.9107 102\n","loss  279  -  tensor(0.3355, grad_fn=<NllLossBackward>)\n","Train Loss 279: 0.3355 Acc: 0.9018 101\n","loss  280  -  tensor(0.3350, grad_fn=<NllLossBackward>)\n","Train Loss 280: 0.3350 Acc: 0.9018 101\n","loss  281  -  tensor(0.3345, grad_fn=<NllLossBackward>)\n","Train Loss 281: 0.3345 Acc: 0.9018 101\n","loss  282  -  tensor(0.3340, grad_fn=<NllLossBackward>)\n","Train Loss 282: 0.3340 Acc: 0.9018 101\n","loss  283  -  tensor(0.3335, grad_fn=<NllLossBackward>)\n","Train Loss 283: 0.3335 Acc: 0.9018 101\n","loss  284  -  tensor(0.3330, grad_fn=<NllLossBackward>)\n","Train Loss 284: 0.3330 Acc: 0.9018 101\n","loss  285  -  tensor(0.3325, grad_fn=<NllLossBackward>)\n","Train Loss 285: 0.3325 Acc: 0.9018 101\n","loss  286  -  tensor(0.3320, grad_fn=<NllLossBackward>)\n","Train Loss 286: 0.3320 Acc: 0.9018 101\n","loss  287  -  tensor(0.3316, grad_fn=<NllLossBackward>)\n","Train Loss 287: 0.3316 Acc: 0.9018 101\n","loss  288  -  tensor(0.3311, grad_fn=<NllLossBackward>)\n","Train Loss 288: 0.3311 Acc: 0.9018 101\n","loss  289  -  tensor(0.3306, grad_fn=<NllLossBackward>)\n","Train Loss 289: 0.3306 Acc: 0.9018 101\n","loss  290  -  tensor(0.3301, grad_fn=<NllLossBackward>)\n","Train Loss 290: 0.3301 Acc: 0.9018 101\n","loss  291  -  tensor(0.3296, grad_fn=<NllLossBackward>)\n","Train Loss 291: 0.3296 Acc: 0.9018 101\n","loss  292  -  tensor(0.3291, grad_fn=<NllLossBackward>)\n","Train Loss 292: 0.3291 Acc: 0.9018 101\n","loss  293  -  tensor(0.3287, grad_fn=<NllLossBackward>)\n","Train Loss 293: 0.3287 Acc: 0.9018 101\n","loss  294  -  tensor(0.3282, grad_fn=<NllLossBackward>)\n","Train Loss 294: 0.3282 Acc: 0.9018 101\n","loss  295  -  tensor(0.3277, grad_fn=<NllLossBackward>)\n","Train Loss 295: 0.3277 Acc: 0.9018 101\n","loss  296  -  tensor(0.3273, grad_fn=<NllLossBackward>)\n","Train Loss 296: 0.3273 Acc: 0.9018 101\n","loss  297  -  tensor(0.3268, grad_fn=<NllLossBackward>)\n","Train Loss 297: 0.3268 Acc: 0.9018 101\n","loss  298  -  tensor(0.3263, grad_fn=<NllLossBackward>)\n","Train Loss 298: 0.3263 Acc: 0.9018 101\n","loss  299  -  tensor(0.3259, grad_fn=<NllLossBackward>)\n","Train Loss 299: 0.3259 Acc: 0.9018 101\n"]}]},{"cell_type":"code","metadata":{"id":"XYiK6cjqWPrv","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1635254788981,"user_tz":-540,"elapsed":294,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"b715ba5d-e8ea-4ddd-ec52-c1693a66e6ec"},"source":["import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","ax = fig.add_subplot()\n","ax.plot(list(range(len(acc))),acc )\n","ax.set_xlabel('#epoch')\n","ax.set_ylabel('accuracy')\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"Ugf3YAFeu9Rz"},"source":["C++のコードは手作業で修正しています。"]},{"cell_type":"code","metadata":{"id":"ERcQTqId1ymt"},"source":["!g++ -std=c++14 ./src/cse1.cpp ./src/cse1_param.cpp ./src/cse1_train.cpp -D_NOTEBOOK -I ../../../xtensor -lcblas -o ./src/cse1_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Yvq5MIhdz-X","executionInfo":{"status":"ok","timestamp":1635254892607,"user_tz":-540,"elapsed":761,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"d13d8abe-173d-4291-f9d0-455cd60f912a"},"source":["!./src/cse1_train"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["### forward computation ...\n"," 1.160111\n","### backward computation ...\n","input_grad{{ 0.000388, -0.000082,  0.001442, -0.001026},\n"," {-0.00163 , -0.000588,  0.000393, -0.000363},\n"," {-0.002082, -0.001018,  0.001658, -0.000565},\n"," {-0.000511, -0.000123, -0.000648, -0.001045},\n"," { 0.000757,  0.001132, -0.000851,  0.000955},\n"," {-0.001367, -0.000591,  0.000333, -0.000317},\n"," { 0.000456,  0.001472, -0.00038 ,  0.000768},\n"," { 0.000484,  0.001022, -0.000164,  0.000845},\n"," { 0.000975, -0.000376,  0.001201,  0.000455},\n"," {-0.001371, -0.000598,  0.000337, -0.000316},\n"," { 0.001298,  0.00068 , -0.00096 ,  0.000676},\n"," { 0.000912,  0.000498, -0.000053,  0.000358},\n"," {-0.000279, -0.000499,  0.000339, -0.001631},\n"," {-0.001483,  0.000332,  0.00037 ,  0.000355},\n"," {-0.001265, -0.000566,  0.000409, -0.000314},\n"," { 0.001179,  0.000775, -0.000708,  0.000957},\n"," {-0.001308, -0.000458,  0.00041 , -0.000462},\n"," {-0.000392, -0.000395, -0.00008 , -0.001208},\n"," {-0.000253, -0.000395,  0.00061 , -0.00073 },\n"," {-0.001342, -0.000488,  0.000417, -0.000294},\n"," {-0.001888, -0.000564,  0.000313, -0.000308},\n"," { 0.000954,  0.000904, -0.001179,  0.001008},\n"," {-0.001875, -0.000513,  0.000323, -0.000292},\n"," { 0.001197, -0.000481,  0.001432, -0.00016 },\n"," {-0.000252,  0.000951,  0.000034,  0.000131},\n"," { 0.000942,  0.000537, -0.000134,  0.000346},\n"," {-0.001351, -0.000602,  0.00034 , -0.000309},\n"," {-0.0005  ,  0.000576,  0.001084,  0.000597},\n"," { 0.001154,  0.000688, -0.000999,  0.000723},\n"," {-0.001128, -0.000444,  0.000379, -0.00048 },\n"," {-0.001301, -0.00055 ,  0.000313, -0.000244},\n"," {-0.000219, -0.000649, -0.000485, -0.001153},\n"," { 0.000941,  0.001367, -0.001342,  0.000899},\n"," { 0.000485,  0.000892, -0.000115,  0.000706},\n"," { 0.000553,  0.000179, -0.001148,  0.000162},\n"," {-0.000945,  0.000009, -0.000137, -0.001615},\n"," { 0.000464,  0.001002, -0.000134,  0.000889},\n"," {-0.000229,  0.000818,  0.001241,  0.000472},\n"," {-0.001741,  0.000805,  0.00084 ,  0.000455},\n"," {-0.001092, -0.000477,  0.000311, -0.000536},\n"," {-0.000561, -0.000155, -0.000627, -0.001217},\n"," {-0.000541,  0.000075, -0.000304, -0.001565},\n"," { 0.000378,  0.000834, -0.000431,  0.000961},\n"," {-0.001458, -0.000459,  0.000125, -0.000183},\n"," { 0.000426,  0.000464,  0.000922, -0.000063},\n"," { 0.000196,  0.000857, -0.000707,  0.000899},\n"," {-0.001443,  0.000314,  0.000363,  0.000348},\n"," { 0.001253,  0.000977, -0.000619,  0.000496},\n"," { 0.000548,  0.000861, -0.000445,  0.000534},\n"," {-0.000605,  0.000158, -0.000241, -0.000767},\n"," {-0.00151 , -0.000643,  0.000116, -0.000175},\n"," { 0.001026, -0.001392,  0.000786, -0.000692},\n"," {-0.001242, -0.000497,  0.000396, -0.000508},\n"," { 0.000214, -0.000455,  0.000814, -0.000886},\n"," {-0.001346, -0.000381,  0.000296, -0.000435},\n"," {-0.001398, -0.000822,  0.000778, -0.000632},\n"," {-0.001967,  0.000427,  0.000596,  0.0002  },\n"," { 0.000844, -0.00025 ,  0.001146, -0.000162},\n"," { 0.000093,  0.000445,  0.00058 ,  0.000359},\n"," {-0.001361, -0.000466,  0.000503, -0.000484},\n"," {-0.000265, -0.000376,  0.000253, -0.001532},\n"," { 0.00053 ,  0.000852, -0.000541,  0.000614},\n"," { 0.000078, -0.000669, -0.000284, -0.001589},\n"," { 0.000642,  0.000729, -0.000641,  0.000656},\n"," { 0.000707,  0.000567,  0.000806,  0.000646},\n"," { 0.000451,  0.00035 ,  0.000668,  0.000017},\n"," {-0.001079, -0.000228, -0.000172,  0.000006},\n"," {-0.001482, -0.000637,  0.000117, -0.00017 },\n"," { 0.000955,  0.001519, -0.000073,  0.000292},\n"," {-0.001538,  0.000395,  0.000362,  0.000355},\n"," { 0.00107 ,  0.000842, -0.001367,  0.00064 },\n"," { 0.000894, -0.001289,  0.00097 , -0.000545},\n"," {-0.000356, -0.000125,  0.000065, -0.001489},\n"," { 0.000649,  0.000376,  0.001578,  0.000094},\n"," {-0.001475,  0.00033 ,  0.000368,  0.000353},\n"," { 0.001397,  0.00082 , -0.000765,  0.000629},\n"," {-0.000149,  0.000715,  0.000899,  0.000796},\n"," {-0.00143 , -0.00007 ,  0.000143, -0.00019 },\n"," {-0.001377, -0.000573,  0.000331, -0.000315},\n"," { 0.00073 , -0.001111,  0.000936, -0.000634},\n"," {-0.001327, -0.000645,  0.000297, -0.000358},\n"," { 0.000995,  0.00115 , -0.000971,  0.00079 },\n"," {-0.001523, -0.000331,  0.000511,  0.000045},\n"," { 0.001005,  0.000984, -0.001194,  0.000857},\n"," {-0.00053 , -0.000138, -0.000648, -0.001055},\n"," { 0.000941,  0.001367, -0.001342,  0.000899},\n"," { 0.000706,  0.000988, -0.000755,  0.000745},\n"," {-0.001382, -0.00068 ,  0.000412, -0.000346},\n"," {-0.001357, -0.000426,  0.000377, -0.00047 },\n"," {-0.001238, -0.000508,  0.000383, -0.000497},\n"," {-0.00044 , -0.000166,  0.000201, -0.00118 },\n"," { 0.00082 , -0.001247,  0.000843, -0.00064 },\n"," { 0.000741,  0.001267, -0.000672,  0.000911},\n"," {-0.001451, -0.000463,  0.000128, -0.00018 },\n"," { 0.001398,  0.000806, -0.000808,  0.000577},\n"," { 0.001104,  0.001049, -0.00057 ,  0.000492},\n"," {-0.001515, -0.000635,  0.000112, -0.000178},\n"," { 0.0008  ,  0.000609,  0.000753,  0.000567},\n"," { 0.000391,  0.000371,  0.000964,  0.000009},\n"," {-0.001416, -0.00058 ,  0.000325, -0.000334},\n"," { 0.000975,  0.000793, -0.000603,  0.000633},\n"," {-0.000836, -0.000142, -0.000595, -0.000539},\n"," { 0.000539, -0.000167,  0.001209, -0.000834},\n"," {-0.000288,  0.000151, -0.000664, -0.00129 },\n"," {-0.000679, -0.000227, -0.00027 , -0.001046},\n"," {-0.001231, -0.000506,  0.000382, -0.000495},\n"," {-0.000308, -0.000323,  0.000325, -0.001612},\n"," {-0.000508, -0.000118, -0.00062 , -0.001053},\n"," { 0.000444,  0.001067, -0.000092,  0.000637},\n"," { 0.001381,  0.000798, -0.000708,  0.000642},\n"," { 0.000216,  0.001013,  0.00001 ,  0.000676},\n"," {-0.000155, -0.000713, -0.000527, -0.001088}}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ac-_IZA4d5dG","executionInfo":{"status":"ok","timestamp":1635254900677,"user_tz":-540,"elapsed":295,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"7c19b41f-4c7d-48c7-d8d8-d1ef36b6d282"},"source":["f = open('./src/cse1.out', 'r')\n","\n","loss = []\n","acc=[]\n","\n","datalist = f.readlines()\n","for data in datalist:\n","  #print(data)\n","  ds = data.split(',')\n","  loss.append( float(ds[0]) )\n","  acc.append( float(ds[1]) )\n","\n","f.close()\n","\n","print(\"epoch =\", len(loss))\n","print( loss )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch = 300\n","[1.162463, 1.137182, 1.112908, 1.089613, 1.067268, 1.045844, 1.025309, 1.005637, 0.986794, 0.968748, 0.951466, 0.93492, 0.919077, 0.903905, 0.889377, 0.875462, 0.862132, 0.84936, 0.837119, 0.825382, 0.814129, 0.803331, 0.792966, 0.783012, 0.77345, 0.764258, 0.755418, 0.746911, 0.73872, 0.73083, 0.723225, 0.715891, 0.708814, 0.701981, 0.69538, 0.688999, 0.682828, 0.676856, 0.671074, 0.665472, 0.660042, 0.654774, 0.649662, 0.644699, 0.639877, 0.63519, 0.630632, 0.626197, 0.621879, 0.617673, 0.613574, 0.609578, 0.605681, 0.601878, 0.598165, 0.594539, 0.590995, 0.587531, 0.584144, 0.58083, 0.577587, 0.574412, 0.571303, 0.568256, 0.565271, 0.562344, 0.559473, 0.556658, 0.553896, 0.551184, 0.548521, 0.545906, 0.543337, 0.540812, 0.53833, 0.53589, 0.53349, 0.531131, 0.52881, 0.526526, 0.524277, 0.522063, 0.519883, 0.517735, 0.515619, 0.513535, 0.51148, 0.509456, 0.507459, 0.505491, 0.503549, 0.501635, 0.499746, 0.497882, 0.496043, 0.494227, 0.492436, 0.490666, 0.488919, 0.487194, 0.48549, 0.483806, 0.482143, 0.4805, 0.478876, 0.477271, 0.475685, 0.474117, 0.472566, 0.471033, 0.469517, 0.468018, 0.466536, 0.46507, 0.463619, 0.462184, 0.460764, 0.459359, 0.457969, 0.456593, 0.455231, 0.453883, 0.452549, 0.451228, 0.44992, 0.448625, 0.447342, 0.446073, 0.444815, 0.44357, 0.442336, 0.441114, 0.439903, 0.438704, 0.437516, 0.436339, 0.435173, 0.434017, 0.432872, 0.431736, 0.430611, 0.429496, 0.428391, 0.427295, 0.426209, 0.425132, 0.424064, 0.423005, 0.421956, 0.420915, 0.419883, 0.418859, 0.417843, 0.416836, 0.415837, 0.414846, 0.413863, 0.412888, 0.411921, 0.410961, 0.410009, 0.409064, 0.408127, 0.407196, 0.406273, 0.405358, 0.404449, 0.403547, 0.402652, 0.401764, 0.400882, 0.400007, 0.399138, 0.398275, 0.397419, 0.396569, 0.395725, 0.394887, 0.394055, 0.393229, 0.392409, 0.391594, 0.390786, 0.389984, 0.389187, 0.388395, 0.38761, 0.386829, 0.386054, 0.385284, 0.384519, 0.383759, 0.383004, 0.382254, 0.381509, 0.380769, 0.380034, 0.379303, 0.378577, 0.377856, 0.377139, 0.376427, 0.375719, 0.375016, 0.374317, 0.373623, 0.372933, 0.372247, 0.371565, 0.370887, 0.370214, 0.369545, 0.368879, 0.368218, 0.367561, 0.366907, 0.366257, 0.365612, 0.364969, 0.364331, 0.363697, 0.363066, 0.362438, 0.361814, 0.361194, 0.360577, 0.359964, 0.359354, 0.358748, 0.358146, 0.357547, 0.356951, 0.356358, 0.355769, 0.355183, 0.3546, 0.35402, 0.353443, 0.35287, 0.3523, 0.351732, 0.351168, 0.350606, 0.350048, 0.349492, 0.348939, 0.348389, 0.347841, 0.347297, 0.346755, 0.346215, 0.345679, 0.345146, 0.344616, 0.344089, 0.343565, 0.343043, 0.342524, 0.342007, 0.341492, 0.34098, 0.340471, 0.339963, 0.339458, 0.338956, 0.338456, 0.337958, 0.337463, 0.336969, 0.336479, 0.33599, 0.335504, 0.33502, 0.334538, 0.334058, 0.333581, 0.333106, 0.332633, 0.332163, 0.331694, 0.331227, 0.330762, 0.330299, 0.329839, 0.32938, 0.328924, 0.32847, 0.328017, 0.327567, 0.327119, 0.326672, 0.326227, 0.325784, 0.325343, 0.324904, 0.324467, 0.324031, 0.323598, 0.323166, 0.322735]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"xMQUBvFqfMWg","executionInfo":{"status":"ok","timestamp":1635254903637,"user_tz":-540,"elapsed":293,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"866c146b-bf1a-4cc7-cfe2-bb621479c5f1"},"source":["# 交差エントロピー誤差\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","ax = fig.add_subplot()\n","ax.plot(list(range(len(loss))), loss)\n","ax.set_xlabel('epoch')\n","ax.set_ylabel('loss')\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"iLif0DtvuYG5","executionInfo":{"status":"ok","timestamp":1635254906665,"user_tz":-540,"elapsed":300,"user":{"displayName":"Mari Hiroshi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18424111801791476769"}},"outputId":"9358ff60-d150-42a2-f9e1-f5ee38e4e150"},"source":["# 正解率\n","fig = plt.figure()\n","ax = fig.add_subplot()\n","ax.plot(list(range(len(acc))), acc)\n","ax.set_xlabel('epoch')\n","ax.set_ylabel('accuracy')\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"OSkuEd7zfizf"},"source":[""],"execution_count":null,"outputs":[]}]}